{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionGenerator:\n",
    "    \n",
    "    IMAGE_WIDTH = 0\n",
    "    IMAGE_HEIGHT = 0\n",
    "    \n",
    "    IMAGE_CLASSIFIER = None\n",
    "    \n",
    "    def __init__(self, image_width, image_height):\n",
    "        self.IMAGE_WIDTH = image_width\n",
    "        self.IMAGE_HEIGHT = image_height\n",
    "        \n",
    "        self.IMAGE_CLASSIFIER = ImageClassifier(image_width, image_height)\n",
    "        self.IMAGE_CLASSIFIER.loadModel()\n",
    "        \n",
    "    def convertPath(self, path):\n",
    "        validPath = \"\"\n",
    "        for char in path:\n",
    "            if char == '\\\\':\n",
    "                validPath += \"/\"\n",
    "            else:\n",
    "                validPath += char\n",
    "        return validPath\n",
    "    \n",
    "    def generateCaption(self, image_path, prediction_model_path=\"ImageClassifier/ImageClassifier.h5\"):\n",
    "        image_path = self.convertPath(image_path)\n",
    "        image = self.readImageFile(image_path)\n",
    "        self.IMAGE_CLASSIFIER.predict(image)\n",
    "    \n",
    "    def readImageFile(self, image_path):\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(\"Unknow path\")\n",
    "            return None\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    \n",
    "    DATASETS_PATH = \"D:/Cours/Cesi/A5/UE/Option - Data Science/Projet/Livrable 2/Datasets/extracted\"\n",
    "    CLASS_NAMES = ['Painting', 'Photo', 'Schematics', 'Sketch', 'Text']\n",
    "    \n",
    "    VALIDATION_SPLIT = 0.3\n",
    "    \n",
    "    IMAGE_WIDTH = 0\n",
    "    IMAGE_HEIGHT = 0\n",
    "    \n",
    "    MODEL = None\n",
    "    EPOCHS = 0\n",
    "    HISTORY = None\n",
    "    \n",
    "    def __init__(self, image_width, image_height):\n",
    "        self.IMAGE_WIDTH = image_width\n",
    "        self.IMAGE_HEIGHT = image_height\n",
    "        \n",
    "    def buildModel(self, dropout_rate=0, kernel_regularizer_l1=0.00, kernel_regularizer_l2=0.0):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomRotation(10),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom((0.2, 0.5)),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\", \n",
    "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", \n",
    "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", \n",
    "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\", \n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\n",
    "            tf.keras.layers.Dense(len(self.CLASS_NAMES))\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer=\"adam\",\n",
    "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           metrics=[\"accuracy\"])\n",
    "        return model\n",
    "        \n",
    "    def fit(self, epochs, save_path=None, show_training_results=False, dropout_rate=0, kernel_regularizer_l1=0.01, kernel_regularizer_l2=0.01):\n",
    "        train_dataset, test_dataset = self.generateDatasets()\n",
    "        self.MODEL = self.buildModel(dropout_rate, kernel_regularizer_l1, kernel_regularizer_l2)\n",
    "        self.EPOCHS = epochs\n",
    "        \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "        self.HISTORY = self.MODEL.fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[callback])\n",
    "        \n",
    "        if save_path != None:\n",
    "            self.MODEL.save(save_path)\n",
    "            \n",
    "        if show_training_results:\n",
    "            self.showTrainingResults()\n",
    "    \n",
    "    def generateDatasets(self):\n",
    "        datasets = []\n",
    "        \n",
    "        for subset_label in ['training', 'validation']:\n",
    "            datasets.append(tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            self.DATASETS_PATH,\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            validation_split=self.VALIDATION_SPLIT,\n",
    "            subset=subset_label,\n",
    "            seed=42,\n",
    "            color_mode=\"rgb\",\n",
    "            image_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT)))\n",
    "        return datasets[0], datasets[1]\n",
    "    \n",
    "    def loadModel(self, model_path=\"ImageClassifier/ImageClassifier.h5\", add_softmax_layer=True):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        if add_softmax_layer:\n",
    "            model.add(tf.keras.layers.Softmax())\n",
    "        self.MODEL = model\n",
    "        \n",
    "    def modelSummary(self):\n",
    "        self.MODEL.summary()\n",
    "        \n",
    "    def predict(self, image, model_path=\"ImageClassifier/ImageClassifier.h5\"):\n",
    "        prediction = self.MODEL.predict(tf.convert_to_tensor(image))\n",
    "        print(self.CLASS_NAMES[np.argmax(prediction)])\n",
    "        \n",
    "    def showTrainingResults():\n",
    "        epochs_range = range(self.EPOCHS)\n",
    "    \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, self.HISTORY.history['accuracy'], label=\"Training accuracy\")\n",
    "        plt.plot(epochs_range, self.HISTORY.history['val_accuracy'], label=\"Validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Training and validation accuracy\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, self.HISTORY.history['loss'], label=\"Training loss\")\n",
    "        plt.plot(epochs_range, self.HISTORY.history['val_loss'], label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Training and validation loss\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49024 files belonging to 5 classes.\n",
      "Using 34317 files for training.\n",
      "Found 49024 files belonging to 5 classes.\n",
      "Using 14707 files for validation.\n",
      "Epoch 1/30\n",
      "  10/1073 [..............................] - ETA: 31:41 - loss: 6.1460 - accuracy: 0.3042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-360a3b39cf42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier1.h5\", show_training_results=True, \n\u001b[0m\u001b[0;32m      3\u001b[0m                      dropout_rate=0, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.0)\n",
      "\u001b[1;32m<ipython-input-4-fc3514280390>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, save_path, show_training_results, dropout_rate, kernel_regularizer_l1, kernel_regularizer_l2)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHISTORY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1133\u001b[0m                 _r=1):\n\u001b[0;32m   1134\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2948\u001b[0m       (graph_function,\n\u001b[0;32m   2949\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2950\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2951\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1928\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1929\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1930\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1931\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1932\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    557\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier1.h5\", show_training_results=True, \n",
    "                     dropout_rate=0, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier2.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.2, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier3.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier4.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.8, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier5.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.01, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier6.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.001, kernel_regularizer_l2=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier7.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.2, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier8.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.0, kernel_regularizer_l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier9.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.01, kernel_regularizer_l2=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier10.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.5, kernel_regularizer_l1=0.001, kernel_regularizer_l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier11.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.8, kernel_regularizer_l1=0.001, kernel_regularizer_l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier12.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.8, kernel_regularizer_l1=0.01, kernel_regularizer_l2=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier13.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.2, kernel_regularizer_l1=0.01, kernel_regularizer_l2=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "image_classifier.fit(epochs=30, save_path=\"ImageClassifier/ImageClassifier14.h5\", show_training_results=True, \n",
    "                     dropout_rate=0.2, kernel_regularizer_l1=0.001, kernel_regularizer_l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#captionGenerator = CaptionGenerator(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "#captionGenerator.generateCaption(\"D:/Cours/Cesi/A5/UE/Option - Data Science/Projet/Dataset soutenance/Text  (4).png\")\n",
    "#captionGenerator.generateCaption(\"D:/Cours/Cesi/A5/UE/Option - Data Science/Projet/Dataset soutenance/Paint  (1).jpg\", \n",
    "#                                 prediction_model_path=\"ImageClassifier/ImageClassifierFullPainting.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

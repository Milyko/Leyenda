{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HETjw6mfjVh6"
      },
      "source": [
        "import cv2\r\n",
        "import imageio\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from nltk.translate.bleu_score import corpus_bleu\r\n",
        "import numpy as np\r\n",
        "from numpy import argmax\r\n",
        "import os\r\n",
        "from pickle import dump, load\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "from scipy.ndimage import gaussian_filter, uniform_filter\r\n",
        "import string\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "from tensorflow.keras.layers import add\r\n",
        "from tensorflow.keras.models import Model, load_model\r\n",
        "from tensorflow.keras.preprocessing.image import load_img\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToRcOKocjhDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a3554e-5194-493a-e593-5c94b8f48a16"
      },
      "source": [
        "IMAGE_WIDTH = 224\r\n",
        "IMAGE_HEIGHT = 224\r\n",
        "\r\n",
        "ROOT_DIR = \"drive/MyDrive/Colab Notebooks\"\r\n",
        "\r\n",
        "DATASET_PATH = os.path.join(ROOT_DIR, \"Dataset\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_PATH = os.path.join(ROOT_DIR, \"CaptionGenerator\")\r\n",
        "CAPTION_GENERATOR_DATASET_PATH = os.path.join(CAPTION_GENERATOR_PATH, \"Dataset\")\r\n",
        "CAPTION_GENERATOR_IMAGE_DATASET_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"Flicker8k_Dataset\")\r\n",
        "CAPTION_GENERATOR_TEXT_DATASET_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"Text\")\r\n",
        "CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"fit\")\r\n",
        "CAPTION_GENERATOR_IMAGES_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"img\")\r\n",
        "print(CAPTION_GENERATOR_TEXT_DATASET_PATH)\r\n",
        "\r\n",
        "CAPTION_GENERATOR_DESCRIPTIONS_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"descriptions.txt\")\r\n",
        "CAPTION_GENERATOR_FEATURES_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"features.pkl\")\r\n",
        "CAPTION_GENERATOR_TOKENIZER_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"tokenizer.pkl\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_TOKEN_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr8k.token.txt\")\r\n",
        "CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr_8k.trainImages.txt\")\r\n",
        "CAPTION_GENERATOR_TEST_IMAGES_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr_8k.devImages.txt\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_TRAINING_EPOCHS = 20"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Colab Notebooks/CaptionGenerator/Dataset/Text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdtqVO6tZuDd"
      },
      "source": [
        "class ImageLoader:\r\n",
        "  def convolve(self, image_data, filter, parameter=3):\r\n",
        "    image_data = image_data[0]\r\n",
        "    if filter == \"\" or filter == \"none\":\r\n",
        "      pass\r\n",
        "    elif filter == \"gaussian\":\r\n",
        "      image_data = self.convolveGaussianFilter(image_data, parameter)\r\n",
        "    elif filter == \"uniform\":\r\n",
        "      image_data = self.convolveUniformFilter(image_data, parameter)\r\n",
        "    else:\r\n",
        "      print(\"Error: Unknown filter '\" + filter + \"'\")\r\n",
        "    image_data = np.expand_dims(image_data, axis=0)\r\n",
        "    return image_data\r\n",
        "\r\n",
        "  def convolveGaussianFilter(self, image_data, sigma=3):\r\n",
        "    return np.array(Image.fromarray(image_data)\r\n",
        "    .filter(ImageFilter.GaussianBlur(sigma)))\r\n",
        "\r\n",
        "  def convolveUniformFilter(self, image_data, size=3):\r\n",
        "    return np.array(Image.fromarray(image_data)\r\n",
        "    .filter(ImageFilter.UnsharpMask(size)))\r\n",
        "    #return gaussian_filter(image_data, size)\r\n",
        "\r\n",
        "  def getImageData(self, image):\r\n",
        "    return np.array(image)\r\n",
        "\r\n",
        "  def readAndShowImage(self, image_path):\r\n",
        "    image_data = self.readImage(image_path)\r\n",
        "    self.showImage(image_data)\r\n",
        "\r\n",
        "  def readImage(self, image_path, target_width, target_height):\r\n",
        "    if os.path.isfile(image_path):\r\n",
        "      #image_data = np.array(Image.open(image_path))\r\n",
        "      image_data = cv2.imread(image_path)[:,:,::-1]\r\n",
        "      image_data = self.resize(image_data, target_width, target_height)\r\n",
        "      image_data = np.expand_dims(image_data, axis=0)\r\n",
        "      return image_data\r\n",
        "    else:\r\n",
        "      print(\"ERROR: Invalid image path\")\r\n",
        "\r\n",
        "  def resize(self, image_data, target_width, target_height):\r\n",
        "    image_data = cv2.resize(image_data, (target_width, target_height))\r\n",
        "    return image_data\r\n",
        "\r\n",
        "  def showImage(self, image_data):\r\n",
        "    if len(image_data.shape) == 4:\r\n",
        "      image_data = image_data[0]\r\n",
        "    plt.imshow(image_data)\r\n",
        "    plt.xticks([])\r\n",
        "    plt.yticks([])\r\n",
        "    plt.show()"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_OK6F_jlFz"
      },
      "source": [
        "class CaptionGenerator:\r\n",
        "    \r\n",
        "    IMAGE_WIDTH = 0\r\n",
        "    IMAGE_HEIGHT = 0\r\n",
        "    \r\n",
        "    IMAGE_CLASSIFIER = None\r\n",
        "    \r\n",
        "    def __init__(self, image_width, image_height):\r\n",
        "        self.IMAGE_WIDTH = image_width\r\n",
        "        self.IMAGE_HEIGHT = image_height\r\n",
        "        \r\n",
        "        #self.IMAGE_CLASSIFIER = ImageClassifier(image_width, image_height)\r\n",
        "        #self.IMAGE_CLASSIFIER.loadModel()\r\n",
        "        \r\n",
        "    def calculateDescriptionMaxLength(self, descriptions):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        return max(len(d.split()) for d in lines)\r\n",
        "        \r\n",
        "    def cleanDescriptions(self, descriptions):\r\n",
        "        table = str.maketrans('', '', string.punctuation)\r\n",
        "        for key, description_list in descriptions.items():\r\n",
        "            for i in range(len(description_list)):\r\n",
        "                description = description_list[i]\r\n",
        "                description = description.split()\r\n",
        "                description = [word.lower() for word in description]\r\n",
        "                description = [w.translate(table) for w in description]\r\n",
        "                description = [word for word in description if len(word)>1]\r\n",
        "                description = [word for word in description if word.isalpha()]\r\n",
        "                description_list[i] = ' '.join(description)\r\n",
        "        \r\n",
        "    def convertPath(self, path):\r\n",
        "        validPath = \"\"\r\n",
        "        for char in path:\r\n",
        "            if char == '\\\\':\r\n",
        "                validPath += \"/\"\r\n",
        "            else:\r\n",
        "                validPath += char\r\n",
        "        return validPath\r\n",
        "    \r\n",
        "    def convertToLines(self, descriptions):\r\n",
        "        all_descriptions = list()\r\n",
        "        for key in descriptions.keys():\r\n",
        "            [all_descriptions.append(d) for d in descriptions[key]]\r\n",
        "        return all_descriptions\r\n",
        "    \r\n",
        "    def convertToVocabulary(self, descriptions):\r\n",
        "        all_descriptions = set()\r\n",
        "        for key in descriptions.keys():\r\n",
        "            [all_descriptions.update(d.split()) for d in descriptions[key]]\r\n",
        "        return all_descriptions\r\n",
        "    \r\n",
        "    def createSequences(self, tokenizer, max_length, description_list, photo, vocab_size):\r\n",
        "        X1, X2, y = list(), list(), list()\r\n",
        "        for description in description_list:\r\n",
        "          sequence = tokenizer.texts_to_sequences([description])[0]\r\n",
        "          for i in range(1, len(sequence)):\r\n",
        "            in_seq, out_seq = sequence[:i], sequence[i]\r\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\r\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\r\n",
        "            X1.append(photo)\r\n",
        "            X2.append(in_seq)\r\n",
        "            y.append(out_seq)\r\n",
        "        return np.array(X1), np.array(X2), np.array(y)\r\n",
        "    \r\n",
        "    def createTokenizer(self, descriptions, verbose=True):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        tokenizer = Tokenizer()\r\n",
        "        tokenizer.fit_on_texts(lines)\r\n",
        "        vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "          print(\"Vocabulary size: %d\" % vocab_size)\r\n",
        "\r\n",
        "        return tokenizer, vocab_size\r\n",
        "    \r\n",
        "    def dataGenerator(self, descriptions, photos, tokenizer, max_length, vocab_size):\r\n",
        "        while 1:\r\n",
        "          for key, desc_list in descriptions.items():\r\n",
        "            photo = photos[key][0]\r\n",
        "            in_img, in_seq, out_word = self.createSequences(tokenizer, max_length, desc_list, photo, vocab_size)\r\n",
        "            yield [in_img, in_seq], out_word\r\n",
        "    \r\n",
        "    def defineModel(self, vocab_size, max_length, verbose=False):\r\n",
        "        # Feature extractor model\r\n",
        "        inputs1 = Input(shape=(4096,))\r\n",
        "        fe1 = Dropout(0.5)(inputs1)\r\n",
        "        fe2 = Dense(256, activation=\"relu\")(fe1)\r\n",
        "        \r\n",
        "        # Sequence model\r\n",
        "        inputs2 = Input(shape=(max_length,))\r\n",
        "        se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\r\n",
        "        se2 = Dropout(0.5)(se1)\r\n",
        "        se3 = LSTM(256)(se2)\r\n",
        "        \r\n",
        "        # Decoder model\r\n",
        "        decoder1 = add([fe2, se3])\r\n",
        "        decoder2 = Dense(256, activation=\"relu\")(decoder1)\r\n",
        "        outputs = Dense(vocab_size, activation=\"softmax\")(decoder2)\r\n",
        "        \r\n",
        "        model = Model(inputs=[inputs1, inputs2], outputs=outputs)\r\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\r\n",
        "        \r\n",
        "        if verbose:\r\n",
        "            print(model.summary())\r\n",
        "            \r\n",
        "        plot_model(model, to_file=\"model.png\", show_shapes=True)\r\n",
        "        \r\n",
        "        return model\r\n",
        "    \r\n",
        "    def evaluateModel(self, model_filename, verbose=True):\r\n",
        "        train_descriptions, train_features = self.loadTrainingDataset(verbose)\r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions, verbose)\r\n",
        "        max_length = self.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "        test_descriptions, test_features = self.loadTestSet()\r\n",
        "        model = load_model(model_filename)\r\n",
        "        \r\n",
        "        actual, predicted = list(), list()\r\n",
        "        for key, description_list in test_descriptions.items():\r\n",
        "            yhat = self.generateDescription(model, tokenizer, test_features[key], max_length)\r\n",
        "            references = [d.split() for d in description_list]\r\n",
        "            actual.append(references)\r\n",
        "            predicted.append(yhat.split())\r\n",
        "            \r\n",
        "        print(\"Evaluated model: %s\" % model_filename)\r\n",
        "        print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\r\n",
        "        print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\r\n",
        "        print(\"BLEU-3: %f\" % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\r\n",
        "        print(\"BLEU-4: %f\" % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\r\n",
        "\r\n",
        "    def evaluateModels(self, directory=CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH):\r\n",
        "        for model in os.listdir(directory):\r\n",
        "          if(model.endswith(\".h5\")):\r\n",
        "            self.evaluateModel(os.path.join(directory, model))\r\n",
        "        \r\n",
        "    def extractFeatures(self, filename, output_file=CAPTION_GENERATOR_FEATURES_FILENAME, verbose=1):\r\n",
        "        model = VGG16()\r\n",
        "        model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\r\n",
        "        if(verbose >= 2):\r\n",
        "            print(model.summary())\r\n",
        "\r\n",
        "        if isinstance(filename, np.ndarray):\r\n",
        "            image = preprocess_input(filename)\r\n",
        "            feature = model.predict(image, verbose=0)\r\n",
        "            return feature\r\n",
        "\r\n",
        "        else:            \r\n",
        "            if os.path.isdir(filename):\r\n",
        "                features = dict()\r\n",
        "                for name in os.listdir(filename):\r\n",
        "                    filename = filename + '/' + name\r\n",
        "                    image = load_img(filename, target_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "                    image = img_to_array(image)\r\n",
        "                    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\n",
        "                    image = preprocess_input(image)\r\n",
        "                    feature = model.predict(image, verbose=0)\r\n",
        "                    image_id = name.split('.')[0]\r\n",
        "                    features[image_id] = feature\r\n",
        "                    if(verbose >= 3):\r\n",
        "                        print('>%s' % name) \r\n",
        "            \r\n",
        "                if verbose >= 1:\r\n",
        "                    print(\"Extracted Features: %d\" % len(features))\r\n",
        "                \r\n",
        "                dump(features, open(DATASET_PATH + output_file, 'wb'))\r\n",
        "            \r\n",
        "                return features\r\n",
        "                \r\n",
        "            elif os.path.isfile(filename):\r\n",
        "                image = load_img(filename, target_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "                image = img_to_array(image)\r\n",
        "                image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\n",
        "                image = preprocess_input(image)\r\n",
        "                feature = model.predict(image, verbose=0)\r\n",
        "                return feature\r\n",
        "            \r\n",
        "    \r\n",
        "    def fitCaptioningModel(self, train_descriptions, train_features, tokenizer, vocab_size, max_length, epochs=20):\r\n",
        "        model = self.defineCaptioningModel(vocab_size, max_length, summarize=True)\r\n",
        "        steps = len(train_descriptions)\r\n",
        "        for i in range(epochs):\r\n",
        "            generator = self.dataGenerator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\r\n",
        "            model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=2)\r\n",
        "            model.save(os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % i))\r\n",
        "\r\n",
        "    def fitTrainingModelWithProgressiveLoading(self, \r\n",
        "                                               verbose=True, \r\n",
        "                                               epochs=CAPTION_GENERATOR_TRAINING_EPOCHS,\r\n",
        "                                               initial_epoch=0):\r\n",
        "        train_descriptions, train_features = self.loadTrainingDataset(verbose)\r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions, verbose)\r\n",
        "        max_length = self.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "        if initial_epoch == 0:\r\n",
        "          model = self.defineModel(vocab_size, max_length, verbose)\r\n",
        "        else:\r\n",
        "          model_path = os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % int(initial_epoch - 1))\r\n",
        "          model = load_model(model_path)\r\n",
        "          if verbose:\r\n",
        "            print(\"Load model %s\" % model_path)\r\n",
        "\r\n",
        "        for epoch in range(initial_epoch, epochs):\r\n",
        "          print(\"Epoch %d\" % epoch)\r\n",
        "          generator = self.dataGenerator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\r\n",
        "          model.fit(generator, epochs=1, steps_per_epoch=len(train_descriptions))\r\n",
        "          model.save(os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % epoch))\r\n",
        "    \r\n",
        "    def generateAndSaveTokenizer(self, \r\n",
        "                                 filename=CAPTION_GENERATOR_TOKENIZER_FILENAME,\r\n",
        "                                 verbose=True, \r\n",
        "                                 descriptions_filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME):\r\n",
        "        train = self.loadSet(CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME)\r\n",
        "        if verbose:\r\n",
        "            print(\"Dataset: %d\" % len(train))\r\n",
        "        \r\n",
        "        train_descriptions = self.loadCleanDescriptions(train, filename=descriptions_filename)\r\n",
        "        if verbose:\r\n",
        "            print(\"Descriptions: train=%d\" % len(train_descriptions))\r\n",
        "        \r\n",
        "        tokenizer = self.createTokenizer(train_descriptions)\r\n",
        "        dump(tokenizer, open(filename, \"wb\"))\r\n",
        "        \r\n",
        "        if verbose:\r\n",
        "            print(\"Tokenizer saved to file '\" + filename + \"'\")\r\n",
        "    \r\n",
        "    def generateCaption(self, \r\n",
        "                        image_path, \r\n",
        "                        show_image=True, \r\n",
        "                        captioning_model=os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_0.h5\")):\r\n",
        "    #    image_path = self.convertPath(image_path)\r\n",
        "    #    image = self.readImageFile(image_path)\r\n",
        "    #    self.IMAGE_CLASSIFIER.predict(image)\r\n",
        "        #print(os.path.join(CAPTION_GENERATOR_IMAGES_PATH, image_path))\r\n",
        "        #if not os.path.isfile(os.path.join(CAPTION_GENERATOR_IMAGES_PATH, image_path)):\r\n",
        "        #    print(\"Invalid image path\")\r\n",
        "        #    return\r\n",
        "    \r\n",
        "        tokenizer = load(open(CAPTION_GENERATOR_TOKENIZER_FILENAME, \"rb\"))\r\n",
        "        max_length = 34\r\n",
        "        model = load_model(captioning_model)\r\n",
        "        \r\n",
        "        #if show_image:\r\n",
        "        #    image = plt.imread(image_path)\r\n",
        "        #    plt.xticks([])\r\n",
        "        #    plt.yticks([])\r\n",
        "        #    plt.imshow(image)\r\n",
        "        #    plt.show()\r\n",
        "            \r\n",
        "        \r\n",
        "        photo = self.extractFeatures(image_path)\r\n",
        "        caption = self.generateDescription(model, tokenizer, photo, max_length)\r\n",
        "        caption = caption[9: len(caption)-7]\r\n",
        "            \r\n",
        "        return caption\r\n",
        "        \r\n",
        "    def generateDescription(self, model, tokenizer, photo, max_length):\r\n",
        "        in_text = \"startseq\"\r\n",
        "        for i in range(max_length):\r\n",
        "            sequence = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "            sequence = pad_sequences([sequence], maxlen=max_length)\r\n",
        "            yhat = model.predict([photo, sequence], verbose=0)\r\n",
        "            yhat = argmax(yhat)\r\n",
        "            word = self.wordFromId(yhat, tokenizer)\r\n",
        "            if word is None:\r\n",
        "                break\r\n",
        "            \r\n",
        "            in_text += ' ' + word\r\n",
        "            \r\n",
        "            if word == 'endseq':\r\n",
        "                break\r\n",
        "        return in_text\r\n",
        "\r\n",
        "    def getMaxLength(self, descriptions):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        return max(len(description.split()) for description in lines)\r\n",
        "        \r\n",
        "    def getTextFileContent(self, filename):\r\n",
        "        file = open(filename, 'r')\r\n",
        "        text = file.read()\r\n",
        "        file.close()\r\n",
        "        return text\r\n",
        "        \r\n",
        "    def loadCleanDescriptions(self, \r\n",
        "                              dataset, \r\n",
        "                              descriptions_filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME):\r\n",
        "        doc = self.getTextFileContent(descriptions_filename)\r\n",
        "        descriptions = dict()\r\n",
        "        for line in doc.split('\\n'):\r\n",
        "            tokens = line.split()\r\n",
        "            image_id, image_description = tokens[0], tokens[1:]\r\n",
        "            if image_id in dataset:\r\n",
        "                if image_id not in descriptions:\r\n",
        "                    descriptions[image_id] = list()\r\n",
        "                description = 'startseq ' + ' '.join(image_description) + ' endseq'\r\n",
        "                descriptions[image_id].append(description)\r\n",
        "        return descriptions\r\n",
        "\r\n",
        "    def loadDescriptions(self, filename):\r\n",
        "        text = self.getTextFileContent(filename)\r\n",
        "\r\n",
        "        mapping = dict()\r\n",
        "        for line in text.split('\\n'):\r\n",
        "            tokens = line.split()\r\n",
        "            if len(line) < 2:\r\n",
        "                continue\r\n",
        "            image_id, image_description = tokens[0], tokens[1:]\r\n",
        "            image_id = image_id.split('.')[0]\r\n",
        "            image_description = ' '.join(image_description)\r\n",
        "            if image_id not in mapping:\r\n",
        "                mapping[image_id] = list()\r\n",
        "            mapping[image_id].append(image_description)\r\n",
        "        return mapping\r\n",
        "    \r\n",
        "    def loadPhotoFeatures(self, dataset, features_filename=CAPTION_GENERATOR_FEATURES_FILENAME):\r\n",
        "        all_features = load(open(features_filename, 'rb'))\r\n",
        "        features = {k: all_features[k] for k in dataset}\r\n",
        "        return features\r\n",
        "    \r\n",
        "    def loadSet(self, filename):\r\n",
        "        doc = self.getTextFileContent(filename)\r\n",
        "        dataset = list()\r\n",
        "        for line in doc.split('\\n'):\r\n",
        "            if len(line) < 1:\r\n",
        "                continue\r\n",
        "            identifier = line.split('.')[0]\r\n",
        "            dataset.append(identifier)\r\n",
        "        return set(dataset)\r\n",
        "\r\n",
        "    def loadTestSet(self, verbose=True):\r\n",
        "        test = self.loadSet(CAPTION_GENERATOR_TEST_IMAGES_FILENAME)\r\n",
        "        test_descriptions = self.loadCleanDescriptions(test)\r\n",
        "        test_features = self.loadPhotoFeatures(test)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "          print(\"Dataset: %d\" % len(test))\r\n",
        "          print(\"Descriptions: test=%d\" % len(test_descriptions))\r\n",
        "          print(\"Photos: test=%d\" % len(test_features))\r\n",
        "\r\n",
        "        return test_descriptions, test_features\r\n",
        "\r\n",
        "    def loadTrainingDataset(self, verbose=True):\r\n",
        "        train = self.loadSet(CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME)\r\n",
        "        train_descriptions = self.loadCleanDescriptions(train)\r\n",
        "        train_features = self.loadPhotoFeatures(train)\r\n",
        "        if verbose:\r\n",
        "          print(\"Dataset: %d\" % len(train))\r\n",
        "          print(\"Descriptions: train=%d\" % len(train_descriptions))\r\n",
        "          print(\"Photos: train=%d\" % len(train_features))\r\n",
        "\r\n",
        "        return train_descriptions, train_features\r\n",
        "    \r\n",
        "    def prepareImageCaptioningTrainDataset(self):\r\n",
        "        descriptions = self.loadDescriptions(CAPTION_GENERATOR_TOKEN_FILENAME)\r\n",
        "        self.cleanDescriptions(descriptions)\r\n",
        "        vocabulary = self.convertToVocabulary(descriptions)\r\n",
        "        self.saveDescriptions(descriptions)\r\n",
        "        \r\n",
        "    def prepareTestDataset(self):\r\n",
        "        filename = CAPTION_GENERATOR_TEST_IMAGES_FILENAME\r\n",
        "        test = self.loadSet(filename)\r\n",
        "        print(\"Dataset: %d\" % len(test))\r\n",
        "        \r\n",
        "        test_descriptions = self.loadCleanDescriptions(test)\r\n",
        "        print(\"Descriptions: test=%d\" % len(test_descriptions))\r\n",
        "        \r\n",
        "        test_features = self.loadPhotoFeatures(CAPTION_GENERATOR_FEATURES_FILENAME, test)\r\n",
        "        print(\"Photos: test=%d\" % len(test_features))\r\n",
        "        \r\n",
        "        return test_descriptions, test_features\r\n",
        "        \r\n",
        "    def prepareTrainingDataset(self):\r\n",
        "        filename = CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME\r\n",
        "        train = self.loadSet(filename)\r\n",
        "        print(\"Dataset: %d\" % len(train))\r\n",
        "        \r\n",
        "        train_descriptions = self.loadCleanDescriptions(train)\r\n",
        "        print(\"Descriptions: train=%d\" %len(train_descriptions))\r\n",
        "        \r\n",
        "        train_features = self.loadPhotoFeatures(train, CAPTION_GENERATOR_FEATURES_FILENAME)\r\n",
        "        print(\"Photos: train=%d\" % len(train_features))   \r\n",
        "        \r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions)\r\n",
        "        print(\"Vocabulary size: %d\" % vocab_size)\r\n",
        "        \r\n",
        "        max_length = self.calculateDescriptionMaxLength(train_descriptions)\r\n",
        "        print(\"Description length: %d\" % max_length)\r\n",
        "        \r\n",
        "        return train_descriptions, train_features, tokenizer, vocab_size, max_length\r\n",
        "    \r\n",
        "    def readImageFile(self, image_path):\r\n",
        "        if not os.path.isfile(image_path):\r\n",
        "            print(\"Unknow path\")\r\n",
        "            return None\r\n",
        "        else:\r\n",
        "            image = cv2.imread(image_path)\r\n",
        "            image = cv2.resize(image, (self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "            image = np.expand_dims(image, axis=0)\r\n",
        "            return image\r\n",
        "        \r\n",
        "    def saveDescriptions(self, \r\n",
        "                         descriptions=None, \r\n",
        "                         filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME,\r\n",
        "                         verbose=True):\r\n",
        "        print(filename)\r\n",
        "        if descriptions == None:\r\n",
        "          descriptions = self.loadDescriptions(CAPTION_GENERATOR_TOKEN_FILENAME)\r\n",
        "          self.cleanDescriptions(descriptions)\r\n",
        "          vocabulary = self.convertToVocabulary(descriptions)\r\n",
        "          \r\n",
        "          if verbose:\r\n",
        "            print(\"Loaded: %d\" % len(descriptions))\r\n",
        "            print(\"Vocabulary size: %d\" % len(vocabulary))\r\n",
        "\r\n",
        "        lines = list()\r\n",
        "        for key, description_list in descriptions.items():\r\n",
        "            for description in description_list:\r\n",
        "                lines.append(key + ' ' + description)\r\n",
        "        data = '\\n'.join(lines)\r\n",
        "        file = open(filename, 'w')\r\n",
        "        file.write(data)\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    def wordFromId(self, integer, tokenizer):\r\n",
        "        for word, index in tokenizer.word_index.items():\r\n",
        "            if index == integer:\r\n",
        "                return word\r\n",
        "        return None"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYVeklxfaNTV"
      },
      "source": [
        "class ImageClassifier:\r\n",
        "\r\n",
        "    IMAGE_CLASSIFIER_PATH = os.path.join(ROOT_DIR, \"ImageClassifier\")\r\n",
        "    FIT_DIR_PATH = os.path.join(IMAGE_CLASSIFIER_PATH, \"fit\")\r\n",
        "    \r\n",
        "    DATASETS_PATH = \"D:/Cours/Cesi/A5/UE/Option - Data Science/Projet/Livrable 2/Datasets/extracted\"\r\n",
        "    CLASS_NAMES = ['Painting', 'Photo', 'Schematics', 'Sketch', 'Text']\r\n",
        "    \r\n",
        "    VALIDATION_SPLIT = 0.3\r\n",
        "    \r\n",
        "    IMAGE_WIDTH = 0\r\n",
        "    IMAGE_HEIGHT = 0\r\n",
        "    \r\n",
        "    MODEL = None\r\n",
        "    EPOCHS = 0\r\n",
        "    HISTORY = None\r\n",
        "    \r\n",
        "    def __init__(self, image_width, image_height, model=\"model_0.780.h5\"):\r\n",
        "        self.IMAGE_WIDTH = image_width\r\n",
        "        self.IMAGE_HEIGHT = image_height\r\n",
        "\r\n",
        "        self.MODEL = load_model(os.path.join(self.FIT_DIR_PATH, model))\r\n",
        "        \r\n",
        "    def buildModel(self, dropout_rate=0, kernel_regularizer_l1=0.00, kernel_regularizer_l2=0.0):\r\n",
        "        model = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomRotation(10),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomZoom((0.2, 0.5)),\r\n",
        "            tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Dropout(dropout_rate),\r\n",
        "            tf.keras.layers.Flatten(),\r\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\", \r\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.Dense(len(self.CLASS_NAMES))\r\n",
        "        ])\r\n",
        "        \r\n",
        "        model.compile(optimizer=\"adam\",\r\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "                           metrics=[\"accuracy\"])\r\n",
        "        \r\n",
        "        plot_model(model, to_file=\"model.png\", show_shapes=True)\r\n",
        "\r\n",
        "        return model\r\n",
        "        \r\n",
        "    def fit(self, \r\n",
        "            epochs, \r\n",
        "            save_path=None, \r\n",
        "            model_filename=\"ImageClassifierModel.h5\",\r\n",
        "            show_training_results=False, \r\n",
        "            dropout_rate=0, \r\n",
        "            kernel_regularizer_l1=0.01, \r\n",
        "            kernel_regularizer_l2=0.01):\r\n",
        "        train_dataset, test_dataset = self.generateDatasets()\r\n",
        "        self.MODEL = self.buildModel(dropout_rate, kernel_regularizer_l1, kernel_regularizer_l2)\r\n",
        "        self.EPOCHS = epochs\r\n",
        "        \r\n",
        "        earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\r\n",
        "        checkpointsCallback = tf.keras.callbacks.ModelCheckpoint(os.path.join(save_path, \"model_{val_accuracy:.3f}.h5\"),\r\n",
        "                                           save_best_only=True,\r\n",
        "                                           save_weights_only=False,\r\n",
        "                                           monitor='val_accuracy')\r\n",
        "        self.HISTORY = self.MODEL.fit(train_dataset, \r\n",
        "                                      validation_data=test_dataset, \r\n",
        "                                      epochs=epochs, \r\n",
        "                                      callbacks=[earlyStoppingCallback, checkpointsCallback])\r\n",
        "        \r\n",
        "        if save_path != None:\r\n",
        "            self.MODEL.save(os.path.join(save_path, model_filename))\r\n",
        "            \r\n",
        "        if show_training_results:\r\n",
        "            self.showTrainingResults()\r\n",
        "    \r\n",
        "    def generateDatasets(self):\r\n",
        "        datasets = []\r\n",
        "        \r\n",
        "        for subset_label in ['training', 'validation']:\r\n",
        "            datasets.append(tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "            self.DATASETS_PATH,\r\n",
        "            labels=\"inferred\",\r\n",
        "            label_mode=\"int\",\r\n",
        "            validation_split=self.VALIDATION_SPLIT,\r\n",
        "            subset=subset_label,\r\n",
        "            seed=42,\r\n",
        "            color_mode=\"rgb\",\r\n",
        "            image_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT)))\r\n",
        "        return datasets[0], datasets[1]\r\n",
        "\r\n",
        "    def isPhoto(self, image_data):\r\n",
        "      if self.MODEL == None:\r\n",
        "        print(\"ERROR: Model is not defined\")\r\n",
        "        return\r\n",
        "      \r\n",
        "      prediction = self.MODEL.predict(image_data)\r\n",
        "      if np.argmax(prediction) == self.CLASS_NAMES.index('Photo'):\r\n",
        "        return True\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "      print(np.argmax(prediction))\r\n",
        "    \r\n",
        "    def loadModel(self, model_path=\"ImageClassifier/ImageClassifier.h5\", add_softmax_layer=True):\r\n",
        "        model = tf.keras.models.load_model(model_path)\r\n",
        "        if add_softmax_layer:\r\n",
        "            model.add(tf.keras.layers.Softmax())\r\n",
        "        self.MODEL = model\r\n",
        "        \r\n",
        "    def modelSummary(self):\r\n",
        "        self.MODEL.summary()\r\n",
        "        \r\n",
        "    def predict(self,\r\n",
        "                image_data,\r\n",
        "                model_path=\"model_0.780.h5\",\r\n",
        "                verbose=False):\r\n",
        "      if not model_path.endswith(\".h5\"):\r\n",
        "        print(\"ERROR: Invalid classifier model\")\r\n",
        "        return\r\n",
        "      \r\n",
        "      print(image_data.shape)\r\n",
        "      model = load_model(os.path.join(self.FIT_DIR_PATH, model_path))\r\n",
        "      #prediction = model.predict(tf.convert_to_tensor(image))\r\n",
        "      prediction = model.predict(image_data)\r\n",
        "      predicted_class_id = np.argmax(prediction)\r\n",
        "      predicted_class = self.CLASS_NAMES[predicted_class_id]\r\n",
        "      print(predicted_class)\r\n",
        "      return predicted_class, predicted_class_id\r\n",
        "        \r\n",
        "    def showTrainingResults():\r\n",
        "        epochs_range = range(self.EPOCHS)\r\n",
        "    \r\n",
        "        plt.figure(figsize=(8, 8))\r\n",
        "        plt.subplot(1, 2, 1)\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['accuracy'], label=\"Training accuracy\")\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['val_accuracy'], label=\"Validation accuracy\")\r\n",
        "        plt.legend()\r\n",
        "        plt.title(\"Training and validation accuracy\")\r\n",
        "\r\n",
        "        plt.subplot(1, 2, 2)\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['loss'], label=\"Training loss\")\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['val_loss'], label=\"Validation loss\")\r\n",
        "        plt.legend()\r\n",
        "        plt.title(\"Training and validation loss\")\r\n",
        "\r\n",
        "        plt.show()"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVa79ynRjuSi",
        "outputId": "5bbe734d-f1f1-4e46-e2f9-9f3d68d765b4"
      },
      "source": [
        "captionGenerator = CaptionGenerator(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "train_descriptions, train_features = captionGenerator.loadTrainingDataset()\r\n",
        "tokenizer, vocab_size = captionGenerator.createTokenizer(train_descriptions)\r\n",
        "max_length = captionGenerator.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "#captionGenerator.defineModel(vocab_size, max_length)\r\n",
        "#captionGenerator.saveDescriptions()\r\n",
        "\r\n",
        "#train_descriptions, train_features = captionGenerator.loadTrainingDataset()\r\n",
        "\r\n",
        "#tokenizer, vocab_size = captionGenerator.createTokenizer(train_descriptions)\r\n",
        "\r\n",
        "#train_dataset, train_features, tokenizer, vocab_size, max_length = captionGenerator.prepareTrainingDataset()\r\n",
        "\r\n",
        "#captionGenerator.fitTrainingModelWithProgressiveLoading(epochs=20)\r\n",
        "\r\n",
        "#captionGenerator.evaluateModels()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n",
            "Vocabulary size: 7579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f7433eeac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "OO-rw_V3ajFL",
        "outputId": "ed190fe9-7cb1-4db2-d7ef-28385b52ebb3"
      },
      "source": [
        "def main(revert=False):\r\n",
        "    # Chargement de l'image\r\n",
        "    imageLoader = ImageLoader()\r\n",
        "    image_path = os.path.join(DATASET_PATH, image_filename)\r\n",
        "    image_data = imageLoader.readImage(image_path, IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "\r\n",
        "    # Affichage initial\r\n",
        "    imageLoader.showImage(image_data) \r\n",
        "\r\n",
        "    if revert:  \r\n",
        "\r\n",
        "      # Convolution\r\n",
        "      image_data = imageLoader.convolve(image_data, filter, size)\r\n",
        "      if filter != \"\":\r\n",
        "        imageLoader.showImage(image_data)  \r\n",
        "\r\n",
        "      # Classification\r\n",
        "      imageClassifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "      if not imageClassifier.isPhoto(image_data):\r\n",
        "        print(\"The given file is not a photo\")\r\n",
        "        return\r\n",
        "\r\n",
        "    else: \r\n",
        "\r\n",
        "      # Classification\r\n",
        "      imageClassifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "      if not imageClassifier.isPhoto(image_data):\r\n",
        "        print(\"The given file is not a photo\")\r\n",
        "        return\r\n",
        "\r\n",
        "      # Convolution\r\n",
        "      image_data = imageLoader.convolve(image_data, filter, size)\r\n",
        "      if filter != \"\":\r\n",
        "        imageLoader.showImage(image_data)\r\n",
        "\r\n",
        "    # Génération de la légende\r\n",
        "    captionGenerator = CaptionGenerator(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "    caption = captionGenerator.generateCaption(image_data)\r\n",
        "    print(caption)\r\n",
        "\r\n",
        "\r\n",
        "image_filename = \"text10.png\"\r\n",
        "filter = \"\"\r\n",
        "size = 1\r\n",
        "revert = False\r\n",
        "main(revert)\r\n",
        "\r\n",
        "\r\n",
        "#image_data = image_data.reshape(image_data.shape[0], image_data.shape[1], image_data.shape[2], 1)\r\n",
        "#image_path = os.path.join(CAPTION_GENERATOR_IMAGE_DATASET_PATH, \"47871819_db55ac4699.jpg\")\r\n",
        "#image_path = os.path.join(DATASET_PATH, \"photo2.jpg\")\r\n",
        "#print(os.path.isfile(image_path))\r\n",
        "#image_data = imageLoader.readImage(image_path)\r\n",
        "#imageLoader.resize(image_data, IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "#image_data = imageLoader.convolveGaussianFilter(image_data, 3)\r\n",
        "#imageLoader.showImage(image_data)"
      ],
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxN1/r/P2fIgEgiCZHEEDEkVFBDaA0/VGkNbbWlerVcFNVWZ9riFkVpVbX0ctXUGq6aWrMYopEIEWQeZJT55Ew583z2eX5/5J71zZFQ7m1x2O/X67zI3muvtfba69nD86zneQREBB4engcf4f3uAA8Pz53BCysPj5vACysPj5vACysPj5vACysPj5vACysPj5sgvpvCQUFBFB4e/hd1hYeHp7S0FAqFQtDYvrsS1vDwcFy9evXP6RUPD08D+vbte8t9/GswD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAsrD4+bwAvrA4xOp8Phw4exevVqbNu2DTU1NbBarTh06BDef/99pKWlwW634+OPP0ZOTg5SU1PhcDjw1ltvgeM4XL58GUSE2bNn49KlSyAi6PV6LF26FEajEQcOHIDFYkF+fj5KSkpgMplw9uxZfPrppzh//jzOnz+PvXv34uTJkzhy5AjMZjNMJhM2bdqEtLQ0/PLLLygvL7/fw/TIwAvrA4yHhwdUKhWEQiEkEgm2bt0KiUSC8PBwHD16FBzHQSAQYOfOnfj9998BAHPnzsUTTzwBgUCAjz76CESELVu2IDAwEDNmzADHcTh9+jQ4jkNmZiY+/fRT+Pn5wdfXFyKRCEqlEsnJyQgJCUFeXh6WLFmC5ORktG/fHnv27EFCQgK6du2KXbt2Ye/evdBqtfd5lB4deGF9gPHy8kJgYCAee+wxjB8/HhEREfD09ESvXr3QtGlT+Pn5QSQSAQD69++PlStXYuTIkUyALl68CAAQCAQIDw9HQkICBAIBtFotmjRpglGjRiEvLw+tW7dGixYtYLfb0bx5cwQGBqJLly4QCATo0KEDRo8ejS5duiAnJwcVFRUYPHgwJkyYgPDwcNY+zz2AiO7416dPH+K5dzgcDpJKpSSTychms5FarSar1UpERImJiaTX64mIKC4ujqxWK509e5bsdjtlZWWRw+GgkydPksPhoNjYWOI4ji5cuEA2m43i4+PJ4XCQyWSitLQ0IiLiOI5sNhvJZDJKTU0lIqLy8nLKyckhq9VKNpuNrl+/ThUVFax/xcXFpNPp7vGoPNz8R8YalT8B3UUWub59+xIf3ZCH56+jb9++uHr1aqOhSPnXYB4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN4EXVh4eN+Gukim7K84llQKBwOX/9fc5uXm78+/6dd287Xbb/6g/f2bZO227sXP/M+v/M+u7Vf1ObtXOH53b3VyvB4VH4sl65coVDBs2DESEI0eOYOrUqS4LpAHgiy++wM8//8y2vf/++0hJSXEpQ0R47733oNPpXOonIhw7duyWDhA3k5aWhkGDBjWou7HjTCYTbDbbLfff6u+b+0dEcDgc0Ov1LvtUKhWOHj162+Nu/vt2/f7b3/4GpVJ5y/O/3djcavxu/hkMBixbtgybN2++ZV0xMTF48803oVKpGm3Tw8MDDofjtuP/R9fxXvNICGvfvn1x9OhRHD16FIsWLUJVVRX+8Y9/YMaMGThz5gwEAgEMBgM++OAD/Pzzz7DZbCguLsaAAQOwcuVKaDQaAMCRI0cQFhbG3MKcF9Hb2xuhoaEIDg5GbW0tHA4H5s2bB7FYjB49ejR6wYkIZrMZarUaACCRSDB//nw8/vjjmDdvHtLT0wEATZo0gYeHB1566SUEBgbi9OnTuHLlCoxGI4gIJSUlaNWqFatn+vTp4DjOpR21Wg2xWAx/f380b96c7auoqMCYMWMwbtw4XL16FWPHjnUZt9jYWGzZsoXV89lnn8HLywsrVqxg7VVXV2PIkCF45plncOXKFSQmJiIiIgIKhaLRm1p1dTV8fHzwj3/8A99++63Lfq1Wi6VLl+Kzzz7DjRs3YDKZsH37dgQFBWH69OnYsmULTp8+DYFAAI1Gg0WLFuGtt97C2LFjcfz4cZfx9fX1RUREBDw8PLBw4UI0bdoUcXFxcDgcrMzFixddbgDe3t7Izs4GEUEikcBkMuG7775D+/btsXz58jueb38Vj4SwOqMmnDhxAl999RWuXbsGhUKBfv364dKlSwAAsVgMk8kEkUgEDw8PiMViiMVitGzZEh4eHgCAkpIS2O32BvUPHjyYTSCFQgGBQIC+fftCLBbDy8urQXmBQAAPDw9UV1fj6NGjAACDwYAXX3wRU6ZMga+vLx5//HGXYyIiIiASidC8eXMkJSUxn9WIiAiXNsLCwlxecyUSCQYMGICioqJbvg4CQNOmTdG5c2eXfSqVClKpFAAgk8kQFhaGjh07onnz5mxMCgoKUFtbi6CgILRv3x7e3t6wWq0QiUQuNw3neYeGhoLjOHz++edYunSpy36NRoP9+/dj2bJl8PPzQ9OmTdG+fXtYLBZwHIfAwEBkZmYygVOpVOjVqxe6dOkClUoFi8XSYIwBoGPHjvD29ka/fv3YjdbDwwMhISFsTGw2Gzw8PODn5weO41BUVASO46BUKhEUFNRgbO4HvIvc/8Bf/X3G8+hxOxe5R0LB9FfBCynPveSReA3m4XkYcFthlcvlD4SGzgkRse+7Rwm73e6itHlQUCqVsFqtkMvlDb6db+ZW186pQX9QcDth5TgORISePXvC4XBArVazQVWr1TCZTHA4HNBoNJDL5bBYLJBKpZDL5VCpVA3qMxgMUCgUTEFRXzsolUpRW1vL2nTu12g0qKioaHAhW7duzfY7+6VSqVi7RORSl0KhYOekVqshkUhgMBjYttraWlRWVkKj0TSYcHa7HdXV1bDb7ZBKpaiqqmL9qaysRFVVlYtZQiqVsnMzm81QqVQoLy+HRCJhddpsNuj1+gbmDK1We8sohoWFhaw9pyYcqNPsymQyVp9EIoFarUZ5eTlkMhk73nntnBr3xnBeD2f9TpOLyWRCTU0NG7P6jBw5EklJSejbty9qamoA1Cmwqqur2fk5NepyuRxt2rRx0dhzHIeysjLk5OQ8OAJ7p7YtogcjYJpSqSSj0UgtW7akmpoamj9/PtntdlKr1fTxxx/T+fPnSS6X08KFC2nGjBl08uRJ6t+/P40aNYpmzpzJAo4R1QUJ++mnn2jSpEk0f/58SkpKopqaGqqtraVNmzZRnz596J133qGioiLS6/WUnp5OZrOZPvjgA2rSpAkLWEZEZLFYCADZbDZau3YtLViwgCwWC61YsYKWLl1KRER2u51kMhlVVVVRSkoKvfLKK8RxHNXU1NBHH31EXbt2pR07dpBOp6OSkhKaMWMGNWnShBYsWEAymYy1VVZWRgkJCTRw4ECqrq6ml156iUJDQ1l//P39KSAggGpra8nhcJBaraYBAwaQxWIhm81Gp0+fpsmTJ5NYLKbIyEhyOBzEcRwVFhbSzp07yWKxsPGx2Wy0evVq+uabb8jhcLhcC4PBQNeuXaPx48dTSEgIzZ49m5RKJTkcDlqwYAENGzaMNm7cSHa7nUaMGEFvvPEGiUQiGjduHCmVSjKZTGQwGEin09GaNWtIKpU2qL+yspLMZjP961//ohkzZpDRaCS1Wk21tbX0008/Uffu3Wn16tWk1Wpdju3duzfl5ORQREQEVVZWEhHR+++/TzExMez89u3bRw6Hg+bMmUNisZiUSiXV1taSVqslqVRKAoGAOnTo0KDuv5LbBUxzuydrQEAAioqK0Lp1a5jNZggEAuh0OjRt2hR2ux1PPvkk8vLyYLVa8fnnn+PcuXPw9vZGWFgYHA6Hy+uOyWSC3W7HiBEjMGzYMDRt2hTbt29Heno6MjMz4enpiUGDBiE/Px85OTmIioqCQCDA1atX0a1bNwiF/zd8lZWViI6OhtFoxJw5c+Dr6wsPDw988skn+PzzzwEAIpEIZrMZ33zzDZo0aYKwsDBmCmrRogUGDhyIJk2aICUlBTdu3ICnpye6du0KHx8fl7v7/PnzsWbNGhw4cAAhISE4cOAAoqOjmcKrQ4cO0Ol0OHHiBADg8uXLaN68ObvoOp0O2dnZGDJkCLp06QKHwwGr1Qpvb28899xz7IkvFArBcRx69+6NAQMGNLgW2dnZKCkpQfPmzTFixAiEhYWxMUlISECrVq2gUChARDh9+jRSUlIwaNAgTJgwAYcPH0ZpaSny8vLg6emJmTNn4scff3SpPy8vD8uXL0d1dTXy8/MRGhoKsVgMnU6H+Ph4nDlzBi1atMDBgweZCc5Jx44d4eXlhcjISGbCycjIwObNmyEW1+lVnU/cH374AY899hgOHz6MkydP4uLFixCJRIiOjkb37t3/8DX6nnErKW7s9yA8Wd0Fh8NBdrvd5el7L3niiScaPAnvBxMnTiSTyfRA9OVmxo8fT3a7/YHqGx+KlIfHTeBDkfLwPAQ8EsKqUqmQmJh4V8dcunQJcrn8rtsiIvatCABWq9Xl7/+F+gvP/0rMZvNttbO3wulw8Gf202azNartvROSk5NRWVl5V9+cRASr1fpftfdX47bCum/fPthsNuzZs+eWZUwmE1JTU1FYWIh58+ahpqYGRqMRQJ1qPicnB+np6eybID09nWVFW7FiBTIzMxv1MKmurm6gznfuO3nyJP7+97/D4XAgOTkZer0ef//731k5jUaDkydPwuFwQC6X4/r16wDAlCgAkJWVhZycHKSkpOD48eNMKRYfH+9yA7l+/TpOnz6NPXv2NJhgTpOVTqdjfXM4HKisrITJZAJRXUa5ffv2ITU1FQqFAnFxcQAAtVqN3Nxc1NbWNjg/ANDr9bBarfj9999dzDBKpRIcx4HjOBw6dAgnTpxo4FRAREhMTHRpH6gzRZWUlKCsrAxnz57F5cuXcf78eWaeAQCpVIobN26wMXKOXW5urovisKKiAhaLBV9++SUSExNhs9nYvitXrjDvo/rX1bmumIjYORmNRuzfv7+B8up+4XbLDQsLC5lGlYiwatUqTJo0CWazGWKxGLGxsRg3bhyAuidEVlYWoqOj0b59e6hUKphMJgB1k2P9+vVo27YtHnvsMQDA4cOH0bNnT7Rr1w7Dhw+HXq+HwWBAeXk5wsPDAdQtMYyLi8PEiRORm5uLnj17QigU1ikABAJs3LgRgYGBcDgcOHv2LJo0aYLHHnsMdrsdpaWlKC0txblz5+Dv7w9vb29cvHgRUVFRKCgoQFZWFgDgwIEDzF5cUlICoVCINm3aYNeuXRg1ahS6dOkCb29vHD58GFeuXIGfnx86duyI3r17QyQSwWQy4fLly6iurmZaZrvdDh8fH1y6dAlRUVHo2LEjTp06hYSEBJhMJmi1WsTHxyMwMBCenp5ISEiA1WpFp06dYLfbERQUBKDOC8hsNiMjIwNxcXEwGAwIDQ1F165d2bjm5ubiu+++w5AhQ9CpUyd07twZAoEACoUC/v7+2L59OwYOHIjdu3fjq6++wsSJE2GxWLB3714IBAKkpqaiQ4cOaNasGYgIUVFRAACFQoGKigrY7XZcvHgRAoEAfn5+yM/PR6tWreDv7w8PDw/IZDL4+/sjJCQEtbW1sNvtICJcuXIFeXl56N27N86dO4dx48YhPT0dPXr0wKVLl9C3b180bdqU2XAvXryIH374AZMmTUL79u0RGhp6z+Z5Y7idsKpUKhiNRixatAgFBQXMc8Nut0MkEqG4uJiV9fPzw/jx42EwGPDuu++ia9eukEqlkEgkEAgE6NKlCwYMGACHwwGBQIAhQ4agdevWAIC3334b6enpsNvtUCqVaNOmDTONtGrVCgKBwOUp59w3c+ZMVFRUQCgUYsKECTAYDPj000/hcDigUqng6emJTz75BJcuXcKAAQPQt29fAHXeMwKBACqVCjExMVCpVGjVqhU8PDzg7+8PuVyOl156CQ6HAzKZDD4+PoiOjka3bt0wcuRIlovVORZ6vR6+vr7stc5qtaJZs2YIDw+HQCCA3W6HwWDA+vXrodfrUVZWhrfeegvZ2dlo164dfH190aJFCxgMBlgsFvj7+wOoe/IEBQXh6tWrmDVrFiQSCWQyGTp37ozWrVvDarVCqVTi448/xqhRo5Cbm8tuZGazGUSEF198EUSE2tpafPjhhwDqzERt27aF1WrFa6+9hhYtWiAiIgIpKSnsRtGlSxe0bNkSZWVlLjfTESNGQKVSgeM4iMViPP744xAIBJg0aRL0ej27NhKJBK+++iqEQiF72jpXwun1etjtdnZj1Ov1MJvN+Mc//oEnn3wSlZWVf8FsvjseeW2w8/wfpUX59J+VVEKh0MVWzHP/4b1ubsOjJKROBAIBWxjA4z7wt1UeHjfBbYWViJhmF6hT8X/wwQd/St2bN29GYmLiLVX4q1evhtls/lPaaozjx4/j9OnT7G+nFnXLli0oLS1t9Jg9e/aw77DS0lJUVlbeM6+k+priW2EymfDWW289UJ5SANi3szvgtsJ6/vx5WCwWzJ07F3a7HdOmTcPWrVuZicJgMDBhvnHjBr755htkZWVh6tSp2LhxIxITE5nZwGq1wmAwsMl+5swZ5Obmwm63o6ysDCqVCgaDgZlrfvvtN1bWYDDAYDBg/vz5eO+999jELSsrw7Rp0/DPf/4TAFBbW4sPPviAmSFkMhnWrVuHtWvXAqiLB/TLL79AoVDgxIkTLAaTk/Xr12PVqlUsNlD9/gB164Gd358+Pj5QKBRYtGgRpk+fDoPBAI7jWICx+mMjkUgwffp0fP3110hJScHXX3/NbkR5eXlMK+zk6tWrzLz1z3/+E7m5uQ3MWB9++CE++eQTrFu3DmVlZUzJ9a9//QtAnb14+vTprC8KhQJffPEFgLr1uosWLUJJSQm+/PJLdv1WrlyJXbt2AQDS09ORnJwMm80GhULBlEEGgwFffvklCgsLXfqzevVqTJs2ja1TBurWV+v1ehiNRmaKW7lyJebPnw+gzmvogw8+gEwmw2effXbbuXivcEthnTlzJhYsWIB9+/ahX79+WLt2LcaOHYu5c+di3759MBqN2LZtm0t8HaVSCaPRiKKiIiQlJaGkpAS1tbWIjY1lC/edk65Dhw4oKSmBTCZDfHw8tm7dyha3A8DAgQORkpICjuOwcOFCiEQi/Pbbb9i8eTMOHDiA0tJSHDlyBIWFhUhJSUFxcTHOnTuHnJwcnDp1CkqlEvv378eePXuYbTM0NBQ2mw1paWmIjIxEWFgYACA/Px9nzpxBeno6QkJC0KxZMxw7dgxSqRTHjx9nQjdgwADs3r0bv/76KwICAhAbG4u0tDSMGjUKa9euRVVVFTIyMmA2m7Fo0SK2uL1Zs2YYPXo0+vfvj5CQEAQEBGDjxo04c+YMKisroVKpkJuby8bRx8cHcrkc58+fR2pqKq5cuQKJROJiTx0+fDiGDh2KPn364ODBg1CpVDh48CCeeOIJVqa4uBg2mw0LFiyAQCBARkYGrly5gnPnzuHSpUtYuHAhkpKScOrUKcTFxeHq1avMnc/Pzw/V1dUoLCxEcXExpFIpTp06hRs3bqCqqsrlree7775DZGQkRo8eje+//x6pqalITExEZmYmUlNTUVJSgpMnT6KwsBDXrl3DgAEDsGPHDnAch4yMDHz77bcgImRlZeH333//cyfyXeKW2uCjR49CJBKhXbt26Ny5M7KystCnTx9IpVJoNBpEREQgLy8P3bt3h1AohNFohFQqRWBgIAsc1rJlSwiFQlitVjRp0gQA2LaioiIYjUZ06NABMpkMOp0OnTp1QrNmzSAQCHDjxg2IxWKEhYXhwoULGDx4MOLj42EwGNClSxcEBwezSSMSidC+fXvU1tZCo9HAx8cHbdq0QUlJCRQKBZo0aYKYmBgQERQKBWw2GwQCAYRCIYuWqNVqodPpYLPZ0KVLF9TU1CA4OBhyuRxt27ZlgpebmwsPDw906tQJmZmZ4DgOvXr1wrVr1xAVFYXy8nJERkbi4sWLGDJkSKNjq1KpUFpaioCAADRt2hRAnUIqKCiILXgwGo3Q6XRQq9Xw8fFBy5Yt0bRp00Y1y9nZ2ejUqRNKSkpgNptZIDinffPChQsYOHAgsrOz0bp1a+a3qtVq4efnh6CgIOZnGxAQgPbt28Nut0OhUMDT0xMcx8Hb2xtyuRwtWrSAXC5HaGgofHx8AACpqano1q0bvLy8cOXKFbRv3x42mw0ymQwhISHw8vJCVVUV2rRpg7KyMnTv3h35+fno0qULMjMzYbPZEBYWhiZNmsBkMqFt27Z/+nyuz+20wW4prE6zw6OoyeV5uHnoTDfOcJI8PI8SbvnN+mdhMplcNMq3IzU19Y41wESE7Ozs/6VrjbZf/7v5TnAGrP5fycvLQ15e3v9cDwD2uv9HaLVapKam/iltPiy43ZNVoVBg2bJlGDt2LNavX48XXngBzzzzDEJCQuBwOKDVajF37lzs2rULFosFqampOH/+PHx8fPDss8/CZrPh3//+N1uMrtfrMXz4cEyaNAlbtmxBZGQkysrKEBsbi4ULF2LXrl148803ERcXx4JYO3nttdewfft2XLp0CV5eXoiJicGLL76IgwcPIjU1FWKxGGfPnsU777zjcg4lJSX44osvMGrUKPTr1w+7d+/G9evXYTKZWJSJ48ePw2QyQalUYsaMGfjpp58wdepU9q0pkUiwaNEizJo1C2azGceOHcMnn3yCwMBAzJgxA5s3b8ayZcswa9YstGrVCtnZ2Xj55ZexevVq9O7dGwkJCUzb6hzXK1euwMfHB+vWrYOPjw+GDh2Kpk2bIjk5GQ6HAzabDZ6enpgyZQp69OiBoqIihISE4IsvvkB+fj4GDRqEOXPm4LvvvsOHH36It99+G7W1tejatSu8vb2Rn5+PPXv2YMSIEUzbbTKZ8Oabb2L9+vWYN28eAOCzzz7Dhx9+iJiYGPTu3RsVFRWoqKhAZGQkzp8/D7FYDB8fH/j7+0Or1aJZs2YoKChg+otRo0ahoKAAffv2xWeffYZly5YhICAAAPDKK6+gZ8+esFgsGDhwIPr06YOAgAD3+KS6lVd6Y78HIVKEzWaj48eP05w5c6i8vJxUKhVlZmaSw+EgnU5Hjz/+OIu5YzQaaefOndSpUydau3YtWSwWMpvNtHXrVnrjjTdo27ZtNH78eNqzZw8tWLCA1q9fTytXrqSOHTvSjh07yGQyUU1NDVksFlq8eLFLHCSiumgMFouFlEolSaVSUqlUVFFRQTabjZ566ikaNmwYDRgwwOWYgoICeuaZZ6iqqorUajWdOnWKunfvTq+//jpt27aNdDodff/999SyZUtavXo1FRQU0OXLl2nIkCF0+vRpVk9CQgIVFRWRTCYjnU5HU6ZMocLCQrLb7VRZWUkOh4PatWtHer2eTCYTqdVqMhgM1LZtWyouLqb+/fs3GFedTkcnTpyg559/nqqqqujHH3+kBQsW0NKlS6l58+b05ZdfUk1NDf3+++9UUVFBZrOZYmNjKTIykvbv309SqZQSExOpsrKSOI6j4OBgKigoIKlUSjKZjLZt20ZPPPEENWvWjLVrtVppx44dNH36dOrYsSPl5ubSzz//TBcuXKCFCxeyMhqNhnJycmju3Ln06aefUnV1NSkUCvrHP/5Bw4cPpzFjxtDevXupsrKSrFYr6fV6stvtNG3aNFIoFERE1KNHDyooKCC5XM7GzW63/3mT80/gdpEi3E5YiYjMZjMLBuZwOFgQNI7jqLq6mpVzOBxkMBhIIpGQTqdj2w0GA6lUKjIajSwAm0qlIr1eT1qtlqqrq8lkMrm0qdFoaPLkySSXy9k2mUzG+sBxHHEcx9qVyWQklUobBAGzWq0u25w3hNraWjIajUREpNPpqKqqinQ6HXEcRxaLhU0uZxtms5m16XA4qLa2lmw2Gy1YsIDsdjv17NnTZSzqj4/dbm/Qr/r9USqVRESk1+tJrVaTVqulyspKNoZms5lsNhsR1d0QJRIJmc1mcjgc7F8iourqapeQKc6yVVVVLtfIZDKRQqEgiURCHMeRXq8nm81GGo3GpZzVaiWVSkVqtZqdu1qtJqlUSnK5nAwGAxsfJyqVim2rrq5usP9B46EN6+Ls+716hdFoNGjevPl9W/x+J+er1+vRrFkz1NbWus/rHQ/jodMGO7nXE9HPz++etnczd3K+TvtiYGDgX90dnnvMI60N5uFxJ3hh5eFxE3hh5eFxEx4ZYXUqZ+5GofYwc7txcPcxqt//m8/lvz23B2FMHglhTUlJwdChQ3Hq1CmMHz++cRsW/tiM9UfcST31y97J9tv1r7H276S8TqfD/PnzG63n5MmTePnll/+r8blV+bvt383H/lFfbj4mPz+frUxzRlx07jt9+jT7+1bX7eb6OI6DXq9vMN73mkdCWIG63CujR4/GqVOnMHfuXJSVlWHmzJmYN28ei3cL1IU4jY6OxldffYV+/frh0KFDLExlY/Fw608aPz8/EBHLTmYwGFzCaL700ksux5rNZvz888945ZVXWB1r1qyBUCjE6tWrUVtbi4kTJ+KXX34BAHz00Ufw9/dHaGgoCgoKGpyjr68vi8borE8kEsHDw8PFJ9UZHbJDhw6NCr3D4YBOp4PRaITdbme+u0SEmpoavP/++zh27BjbPnHiRMTGxuLVV19l5wsAYWFhLJokAPz6669YvHgxmjVr5tKeSqVigeqcXLlyBUOHDgUAJCUlYfny5di0aRMLMHDs2DGcOXPGRcA4jsNTTz2FgwcPsmum0+lw7NgxhIeHQ6fTYdWqVYiIiGAufUSEsWPHAqhzARwzZgyrT6/XY+XKlVi/fj3/ZL1XCAQCDB8+HCdPnkRYWBgef/xxhIaGYv369Vi5ciW+/vprbNy4ERzHITAwEIcPH8ann36KoKAghISEwNvbGwKBAC//accAACAASURBVBMmTGiwrtUZTVEgEECj0eDgwYPsbyKCj48Pc+n69ddfG/RLJBK5OCZ06NABTzzxBAICAtCiRQv4+voyu250dDRatGgBDw+PRs0406dPx4oVK5j55scff8Tw4cMBAF5eXi7tenh4QCwWN6hHIBDA09OTla8vDEKhEAcPHsRvv/0GjuPg6ekJgUCAyspKtGnThvXLWefNTukqlQqffPIJSx/pLOt0WWxsbIC6aI27du1CfHw8E1ahUAixWIzy8nIolUoAgFgshlgshkgkYn1wRnIsKChg0R6drn9EdYEKjhw5wvqblJTE+sdxHEpKSrBz585bRui4l7j1ooh7jcFgQJMmTe5qUYTD4UBZWRl2796NRYsW/YW9u3X7zZs3/6+j2v+ZEBHGjBkDgUCA48eP3+/uwGq1Yvny5RAKhViyZMn97g6Ah9CflYfnYYVPTMXD8xDwSArrnWp3b8fNGsU7xRnh36kAuRM0Gs1dlb8Z57fZnW53Ul+59GdARFCr1Xd9zN1o5OtTX3F4p205tchE5OK/7NQK30/cVlgrKyvZhSciVFZWQiaTQSaTuaS1cMYMqo/dbndJRORML6HRaFy0lzej0WhYcLCMjAyWocw56Z0pFm6eWBzHsWBfBQUF6N+/v0tWO+fEqP9dabVaWQa16dOn48SJEy4mBoVCgaqqKpY53UlVVRUrp9Vq4XA4UFVVhfz8fDZezv5YrVbk5eVBo9G4JJhykpubizNnzkAmkzXqpG+xWBq9aRERpFIpLBaLyz6r1YopU6awMiqVCmq1GpWVlZBKpWwcb+XkbzabIZfLb/n9rVAoXI5NTk6GWq1m18MZxbC+ENe/ZhUVFdiwYQOI6pJT7dixAxKJBBaLBVarlV3D+8bd2M4eFBc5IiJPT096//33yeFwUFFREQUEBNDzzz9PPXv2pMGDB7NytbW1dOjQIZLL5cw9qra2lsrLy4mISKlUUnJyMiUmJtL8+fPpxIkT7Fij0cgyY+v1elqyZAmFhoaSVColX19f6tChA0mlUuaiJhAIyOFwUHFxsYuLnVQqpbZt2xIRUU5ODj3++OMu58JxHJ05c4Y2b97Mtl29epXy8vJoz549FBkZSV999ZWLW+CIESNILBZTWVmZS13e3t7MZXDRokWk0WhIKBSSUChk4yWXyyk8PJxu3LhBISEhtGjRogZ+t0RE27Zto86dO9PgwYPpp59+arD/xIkTVFFR0SBzeFFREQ0dOpSuXr1KJSUlbP/Zs2fplVdeIaI6/9k33niDPvroIxIIBNSjRw8yGAykVqtd/HadOBwOOnv2LI0dO5Y2btzItlutVuaTOmbMGDp79izb9+abb9LevXvJZDKRzWYjX19f0uv1lJWVxa6r85pZrVYSi8X0/fffk8lkoqVLlxIACg0NpaNHj5LZbHZx7furuJ2LnNs+WYcPH47WrVuDiPDGG29g6dKl+OGHH+BwOFhWOABo0aIFevTogR9//JE9NQ0GA1P3JyYmorKyEhcvXkRQUBBiYmLYsRkZGSxP6aVLl9CnTx/06NEDZrMZkZGRyM7OZkmqOI5Dt27dUFRUhBdeeMElooRIJEKnTp0A1JlQIiIiGpyPh4cHi7II1D39HA4Hxo8fj2effRb79+9nEQsBIDg4GJGRkSyyoRNnxjUA7KkbGRmJbt26oX///gDAkjd5eHigS5cuCAkJYVny6uPn54epU6fi5ZdfbvAEB4DY2FiXVItOpk+fjkWLFqFXr16YOnUqO9ZisSA4OBjA/5mI2rVrh27duiEqKgp6vR4mkwkdO3ZsUCcR4cknn8Rzzz3n8pSXy+XQ6XQAgHbt2rnYcIODg+Hj48PShXTt2hVCoRAtWrRgc6Fbt26sP07TmJeXF+bMmYNu3bqhdevWLLvf/c4LxGuD/0SICC+99FIDe+p/w6VLl1imOJ5Hh4fWn/VBQyAQ/CmCCsAlIDYPD+DGCiYenkeNR0JYDQYDS2l/N6SmprJv1r8CrVbbIC8LAJSXl/+pyXuJqNHUD1ar9Q/Hpbq6muW2uZ8oFAqUlJTc727cV9xWWPft24fMzEz2t1NjZrVaceDAAZw/fx7JycmoqKhAZWUltmzZwnLXFBUVwWw2/2HM4BUrVjS6YB6om+g3f+8TEfbt28fWBxMRNBoNCgsLYbPZIJFIoNFocOzYMVRXV6O4uBg7duyAwWCASqUCUCccGzduxKlTpxrU7WyvMYcCoC5p1O+//44DBw6wxfy1tbVwOByYPXs2Dh06hOzsbHAcx1JUbNy4EYcPH0ZOTk6j55mUlIR9+/bh6tWrSEhIaNTEA9SFVz18+DCuX7/OFEr1zTrFxcVISkpysV9yHMc+G2w2G4tNrFarcezYMVRUVLBwrBkZGfjtt99c2kxPT0dRURGAOuVVYmIiZDIZzp8/j/3797MbbVpaGuLj47F//37Wt8OHD+PEiRNITk5u9Nyd420wGO57jhsnbvnNWl5ejh07dqBFixbYsWMH9uzZg5YtW2LYsGGQyWQ4cuQICgoK4OXlhVdffRVPPPEEbty4gZKSEhw4cAAtW7bE+++/D7vdDplMBiJChw4dWP3OrGRyubzBogCnfdZqtTbQxAJ1cWm9vb0xYMAABAcHIzk5GYcOHcLgwYPRrVs3thheqVSic+fOSE1NxZEjR+Dv74+YmBgkJSXht99+wxtvvOFSLxEhNzcXeXl5cDgceOaZZxrEhPrkk08wdOhQlJeXo127dqisrERhYSEGDBgArVaLKVOm4MMPP8RTTz2F0tJSdO7cGWlpaUhLS0O3bt1YljcncrkcJSUluHbtGjQaDYqLi/Hqq69i3LhxLuVSUlKwc+dO/Pzzz5g+fTqWLVuG3NxclnPGz88PmzZtwrVr1xAbGwulUokzZ87glVdewdSpUzF27FgcO3YMKSkpWLFiBSQSCY4ePYqMjAxERETA19cXer2+gX11586dEAgEmDdvHjQaDc6fPw9fX19cvnwZq1evxi+//IIhQ4Zg8eLFaN68Ofbv3w+VSoX09HRMnToVHTp0gLe3N3r37o1PPvkE7dq1c6nfarUiPj4eu3btQv/+/SEWi+Hp6Xm7qfmX4nbCeunSJSQnJ2PdunXYt28fiAgZGRlo164d1Go1AgICsGHDBqxZswYGgwGtW7eGn58f+vXrh3bt2mHmzJnIzMxkHhgVFRXgOM5FWK1WK4xGI8aOHdvAdctpOqlvmqnP22+/DZFIBJ1Oh+DgYHAch4SEBISFhWHChAmQSCRYunQpcnJyEBgYiKioKNTW1iIkJAQmkwlhYWF48cUX0bNnT5d6hUIhZDIZsrKyIBQKMWzYsAZt9+rVCx9//DHzEtq7dy+EQiFUKhUmTZoEIkL//v2ZG5vBYMCgQYMwcOBA9oSqj9FoREBAAHr37o3hw4ejqqqqgXcMULewICAgAH//+9/RqVMniEQiVFRUIDAwEGKxGL6+vmjdujWGDRsGjuPg5eWFtLQ0TJ48GbNmzWLODt26dQMRoWXLlli2bBkOHDgAuVyOsLAweHh4MDOLkyZNmkChUDAhfvvtt+Hh4YEPP/wQx44dY2kxo6OjMXjwYLRq1QpisRhVVVWYOnUqunTpgvz8fHTt2hVqtdpFWJ3mOKPRiClTprCEYfeVWxlgG/s9CIsijh8/Tnv27GlgiLfZbLRhwwZKTk6+Tz1rHJPJROvWrbvf3XgoiYuLo9TU1Eb3bd++3SXGs7vw0MYN5uF52OC9bnh4HgLcUli3bNkCIsK2bdtuqZ28WzIyMljUBydqtfoPvU7ef/99cBwHnU4HImrgCODcRkQunjN2ux0GgwFEBJvN5qK4qh+CpT7OhfMGg6FRD5D6WmKtVss8RRwOBxYsWAAiYv1Uq9X4/PPP2XFWq5UlS67/6tVYn5x1Os+j/tuZ8zvxZuovnqf/aFmJqNFljPSfBf30H6Xajz/+6LI/ISHBRUNrMpnYddJqtXfsKXSzo8HNaLVatoT1TjMI/pW4pbBGRESgoqICFouFZbR24rzQFosFcXFxWLx4MdtnNpuRm5vLMpj9/vvvOHz4MADA398fxcXFKC8vx5YtW5CVlQUPDw+WBf3bb7+FUqlEcnIy8vLymLBs3LgRCxcuZCFI9u3bB4fDgTVr1mDZsmVITk6GSCSCSqXCwoULAQBlZWVYtWoVCgsLMX36dGzatImtOz19+jQLM1JfKNavX4/r16/jm2++QVVVFVN2rF27FlqtFjt27GATf82aNRCL63SHAoEADocD3333Hd59912mwTYajdi5cyeAunArW7duxZ49e1h5Z11ZWVm4du0ahEIh8/YxGAzYvHkzzp07B4vFguXLl+PkyZMwmUxQKBSsz++++y4T8lmzZrHrM3PmTIjFYthsNrz33nvsXHNycrBgwQJkZ2ez86uoqMCJEycA1FkBfvjhByxfvhy//PILMjIysHnzZly+fBmbNm1CRkYGPDw82FhaLBaXvuj1epw6dQoOhwOXL1+GUCjEjBkz2I3pxo0bzByo1WoxZ84c7N+/HxKJBMuXL7/LWfrn43baYKBuEb9KpcKLL74IX19fFjMH+D/3sYCAALRp0wYRERGIi4tDVFQUmjVrhpqaGrbYu3Xr1vD19QUAtG/fHhKJBDabDYGBgbhw4QICAwNZOvvevXvD29sbMpnMRSu4Y8cONGvWDNXV1ejYsSOioqLAcRx69+4Nm82GVq1aIT8/H+Hh4ejatSsAoHnz5njssceg0WgwcuRItGvXjgmRr68v0zTXj2fUq1cvBAcHo1+/fjCbzbDZbPDy8kLPnj3h6emJrl27sthDffr0QVlZGaKiopCdnY3u3btj8+bN8PLyQkVFBTp06ACZTIavv/4aQJ1mu1evXvD09IRQKITD4YDRaITVakVQUBD8/PwgFotBRPD29oZGo0GnTp3Qtm1beHp6ora2FomJiYiJiUGLFi2YsAwdOhRCoRAcxzFHBgB4+umn4eXlBZvNhvbt2wOoe7obDAb069cPQUFBEAgEMBqN8Pf3ZykznU/M5557Dj169EDLli3RvXt3GI1GtG/fHkFBQS7OEPVjMQ0dOhQeHh6svdatW0MsFuPpp59m8bL8/PxY7ClPT0+MGzeOabRbtWr1v0zZP4dbaZ4a+z0I2uCbcTgcLOuZ82+DwcD+r9fr6caNG6TValk2Nmd2Mrvd7pLyT6PRkNFoJJ1OR/n5+aTT6UgulzOXM6I6dze1Wt1AG+10X7Pb7S6ZyjiOI6lUyrKjObFYLCwVYX0MBoNLucbQaDSs384scjejUCjI4XAwFz7nT6lUEsdxpFAoWCa4xrBYLGwcG+tj/TEpKiqirKwsMpvNjZbnOI6NT32croXOMvXPi6jO/U2tVrtkrKupqSGtVutSjzMj4F+FzWZr9Fr9FfDaYB4eN4HXBvPwPAS4nbAaDAYoFIq7jsej0+kaXTTPw+MuuJ2went7w+FwMHPI7t27YTAYMHr0aJhMJkyfPh3Tpk3Dd999h/3796OsrAyffvopsrOzMXr0aLz33nuIj4/HunXrYLFYsH//fjz99NP46aef4HA4sHHjRiQmJkKhUGD+/PkNvFLeeecdaLVa7Ny5E6tWrYJWq4VUKoVSqcTGjRuxbt06xMTE4MaNG5DL5Zg4cSJGjx6NZcuWQSKRYM6cOTAajTh79izefvttzJ079w8dCnh4ALingkkmkzHFilKppGeeeYYKCwvp+++/p/LycqqoqCC5XE4ymYzy8/NJIpFQfHw8DRo0iNLS0igpKYntX7ZsGS1fvpwpQJRKJen1elq4cCFNmzaNiouLWbvDhg2jtLQ0stvtJJVKSSaTkd1uJ5vNRj179iSFQkHdu3enQYMGkcViIaVSSfHx8RQcHEwVFRV08eJFqqqqIpVKRWvWrKEOHTrQ0qVLXRRSPI82D52CieM4CIVCpnKvqalB69atodVq4evry9T19B+ju4eHB8xmM7RaLQICAljqB4fDAb1eD6FQiObNm7u0UVtbC6DOlOK0WVZXV7PF4M5xc7ZVWVmJsLAwSCQSiMVitGzZki1KkMlkCA0NZXZhIoJer4dOp0Pz5s2Z+YiHh4/Iz8PjJvDaYB6ehwBeWHl43AReWHl43AReWHl43AReWHl43IRHQlhTUlIwdOhQEBEOHTqEyZMnu0RDtFqt+Pjjj7Fx40a2/bnnnkNcXJyLXycRoVevXiz1hhNnGWf0vvrb6h9/K25lV7u57djYWNTU1DRaZ2Pl7/T3R/1VKpVQKpXM/dDpa3r06FFUVVU1evw///lP5i9a/zd58mT4+/s3OiaNtX8nfb/Tsrc758aOt1qtqK6uvu21u5c8EsLat29fnDlzBufPn8c777yDxMREREVF4cMPP4TRaGTuaStXrsSqVasglUrhcDgwYsQIPPPMMygrKwMAlJaWYsqUKS5uWADQu3dvBAcH48knn2S2X7lcjs6dO6NVq1Y4efJko/2qPzEOHTqE119/HQkJCfj111/RvXt3CIVCbN++nU0mi8WCjz76CAEBAQ3CZwYGBmLatGnMjezrr7+GSCTCF198wdzPnnzySbRs2RLt27fH+PHj8emnn+KFF14AUJdxLTg4GCNGjGgQWTE2NhYxMTFYtWoVcy5/+eWX4eHhgdDQUBARZsyYgaNHj6K6uhopKSnQ6XTIzc1Fs2bNMH36dBeH9AEDBuCNN95o4KReXV3NrpVzXNLS0rBgwQLIZDJIpVLs378fU6ZMQffu3bF9+3aX448dO4auXbtiz549MJvNqKmpQXh4OKqqqpCUlIR+/frB398fI0eOZE72YrGYhW1NTU1FYGAgunfvjurqaubqdyc33HvBIyGsRHVBrlevXo3NmzdDr9fjqaeeQkREBL7++muWJEkmk6FNmzZo3bo1RCIRRCIRXn75ZRbR7+TJk43mSX3xxRcbrDu+ceMGwsPD0bZt21tGxSssLMSWLVtgMplgMBjQv39//L//9//w0ksvYdy4cRCJRCgvL4dKpWK+rUOHDkXnzp3ZQg0nIpEIs2fPdnE6F4lEeO211yAUCnHp0iVUVVWhoqICEyZMwO7du9GtWzccOnSIlY+Ojsa8efNYoicnzz77LE6dOoW33nqLRU4cMmQIQkND2aRPT09Hp06dEBoaipiYGHh6eqJ169ZQqVTYu3cvm+xCoRBisRj/+te/MHPmTJd2OI6DQqGAyWTChg0bYLfbodVq0axZM7Rq1QplZWXw9vZGz549MXnyZEyfPt3l+JYtWyIxMRFnz55FeXk5Nm3aBK1WC6FQiEGDBuHGjRto1qwZjh07xnxdX3jhBZebb3BwMCZPnuySvkSr1eLkyZP3X2Dv5tXhQVlu+KCxYsWKRn1KHzUee+wxKi0tvaWPrROHw0EHDhy4hz37P6Kiom7pd3s7nP7AfzUP3XJDHp6HFX4FEw/PQwAvrDeh0+nYd6ndbm80Ul99bo7udzs4jmM5bR4G6E9WvDhz8PwZ3Ol1kcvl7Lv7TqMi3i/cVlirq6tZFEMnDocDEomkUdOKM5xkY5PB4XBAo9FAo9Fgzpw5LOKhUylTP8FS/eh9AJCTkwOZTMZCfxLVeQEplUpIpVKXkKGlpaUYOHAg65MzGqDBYGg07KnTTOLEWaeznLPd+mVuDq9JRC4B5erjVOioVCooFAqXsdLr9VCr1Q3q0el0zHRjtVpd2pbJZKx9578ajQYqlYqNjXM8iAgSiYS1B9R5Lg0YMMDlXJzXy1mnyWSCXq+HRCKBXq9n41RbW4vq6mo2Hy5evIiKigqYzWaoVKpGb7pEhFatWuHatWsA6kx8RHVhWmtqahoN93o/cVthbdOmDUwmE44ePcpi0hoMBkRGRuLdd991mWgcx0Gv1+PChQt46623Gtxxa2trsWzZMqxfv95FmJcsWYJ33nkHxcXF7Jhnn322wSQeNGgQ06ISEUaNGoV3330XMTExkEqljfZfp9Nhy5YteO6557Bp0yYsXry4gUZZo9G4xCGeNGkSoqOjWba1iRMnYv369ZDJZGwyxsfHNzi/BQsWNNoHiUSCkSNHYvbs2Rg3bhzMZjOkUikUCgXWrFnD4goDdQKxcuVKfPPNN1AqlbBarQ3iFw8ePBgXLlwAx3FITk5GZWUllixZgjlz5sDhcKC6upqNh91uR9euXeFwOFBQUNCoYKSkpGDKlCkA6iIbXr58GefOncOePXsQHR2NTZs2AajLUPfKK6+gTZs2uHDhAogI7733Hp5++mmcO3cOs2fPZjfTxqivlbZYLHjnnXfQvXt3SKXSB8ZsA7ixsEZGRkIoFGLPnj1sUIVCIbp374758+dj9+7drKwzOVJYWBieeuqpBnVlZmZi/PjxWLRoEXr06MF8W9u2bYv8/HxcuXKFBXlu1qyZiynGbDajY8eOOH/+PE6ePAmBQIC0tDRs27YNgYGBCA0NZWU9PT1ZAqyioiJs374d3t7euHr1Kp5//vkG5pibTT5t27ZFQEAAs//Fx8dj4cKFOH36NHva3mxaImo8N6uzfmcCpnbt2iEzMxOff/450tPTcf78eTz55JOsrM1mg6+vL/z8/Jgt2fkkdRIREcHGzsPDAx9//DFiYmLQsmVLCAQCvPXWW+xpKBAIMGbMGFgsFnzwwQfQaDQQi8WIiIhw6bszfrEzxOrIkSPx0ksv4ZVXXmHltm/fDrPZjJ49e6Jp06YAgPDwcAiFQnTp0gVhYWG3FLioqCgWR9oZhtRsNqNTp05s/BsLRH4/eOi0wRqNBuPHj8e5c+fud1d4/keuXbuGrVu3YsOGDQ32bdiwAT4+PuzJ+7DAO5/z8LgJvOmGh+chwG2F9dy5c3/Jh39WVhZLNny3/JGZx4ler0dGRsZ/1UZ9/kj5QUQoLS29bR1WqxWVlZV/2FZ9zbRarf7DRE1KpRKnTp26JxrVO1UCnT179pbfn07tPFCnkMzKymKKvAcFtxNWjUYDIsJrr72GQ4cOISsrC0DdAJ89e5ZdNKvViszMTKSkpDT6/VpWVob09HTk5eUhMTGRqerXr1+Pixcv4uLFiyxD3bVr15CVlcWSLOXm5iIzMxOHDx92MUXYbDYcPHgQdrvdZTG6zWbDpUuXWFjT8vJyrF69GkDdutPMzExkZmYiIyMD8fHxyM3NZf3MysqCRCJBRUUF9Ho94uPjcfToUaZ5ro9T0Vafw4cPIzY2FkCdouS3335DQUEBgDplVEpKCs6cOeNSR1JSEoxGIziOg81mw/Xr15GVlcUm+vXr15mpp7i4GJmZmTCZTDh16hTLQp6VlYXx48fDYrHAarW6mG6OHDnCnCUyMzPZNTQajThy5AgSEhIaXK/y8nJcu3YNRUVFyM7ORm5uLn777TeUlJRAq9UyRZfTrBQXFweNRoPY2FgUFhaC4zhMnDgRCQkJLjfV+mY5p6baYrHg+++/Z9nrzGYzMjMzG80Ofy9xu8RUWq0W8fHxsFqt2LlzJ2w2G7799lu0atUKb775Jq5fv47CwkIEBgZi8eLF8PPzQ01NDTw9PdGrVy94e3vDYrHg9OnTiIuLw6BBg3Dx4kU899xz6NSpE8rKylBVVcUEffLkyfjyyy/h5eWFb7/9FiKRCEuWLMHo0aNx6NAhPPvssyyZU3l5OSZMmIDNmzcjKSkJw4YNw7FjxzBs2DCsXbsWvr6+2LJlCziOQ0VFBS5evAiRSIRt27YhJCQEpaWlqK6uRnR0NBYvXgwfHx/s3LkTkZGR6NChA6RSKZYsWQKJRILk5GSUlpZi6NChaNq0KQ4ePAipVIpp06bhxo0bLAlWamoqvv76a5SXl2Pnzp2YPXs2pk+fjjlz5iAwMBArVqxAdHQ0dDod5HI5fv/9d5aNLTw8HBkZGdi6dSv8/PywePFihISEoLKyEr6+vigvL8fatWsRERGB9PR0LFiwAMePH0dERASSkpLAcRyMRiNsNhvi4uIwefJk/Pzzz1i/fj1ef/11vP3221i4cCGio6MRHR0NhUKBSZMmoWfPnjhz5gw8PT0hFothNptx6tQpxMXF4fnnn4fZbIZYLMaaNWswdOhQvPrqqwgICEBYWBg8PDwglUpx6tQpXL9+HWvWrMGYMWOwcuVKcByHjz/+GEuWLMHYsWMhEAiwf/9+NG/eHM888wxycnIQHh4OjuNQXFyMli1bwmKxIDMzE99//z1ef/11lwRb9xq3e7K2bdsWqamp+Nvf/ob169ejXbt27C49duxYZs8Ti8Xo2LEjRo4ciddffx0FBQUwm83gOA4WiwXh4eGIjo7G4MGDMWnSJAQFBaG6uhrdunWDv78/Zs+eDY7joNVq0adPH0RGRkIkEkGn0yEsLAwTJ05kbmgAmDF95syZuHr1KubPnw+O45CWlgYvLy+MHj0abdu2BQD4+fmhZ8+eKCwsRJMmTdC7d28MHz4cPXv2xIQJE/DYY4+x18zg4GAQER5//HHI5XIMGzaM+YTWf9pfuXIFYrEYHMcxH1OgLmPdyy+/DCLC1atXMWPGDISEhKCiogJCoRCdO3eGj48PzGYzZDIZmjZtimnTprGnallZGYKCgtClSxcWjNyZVrG2thb+/v4YM2YMSktLMX78eIhEIpjNZuj1elaPSCRCUlISgDrb6fz589nTLDw8nHm4OLW7I0eOhMViYauQrFYr2rVrh5iYGDz55JN47rnnMHr0aCxevNgl657VakVxcTGuX7+ORYsWQaFQ4G9/+xuCg4MhEAgwbdo0PPHEE8jOzmbjk5aWhoyMDBAR8zYSiUSIiopCVFQUbDYbjEYjunbtiqeffvqvmdR3CK8NfsDJyspCUFAQQkJC7ndX3IKrV68iICAAbdu2ZX7K7sTttMFu9xr8qBEdHX2/u+BW9O3b93534S/D7V6DeXgeVdxeWIkIZrOZ/QvUaQQrKiqwYsUKAHWmkry8PFitVrao3W63w2q1Ii4uDrGxsXdsYtDriKwPIQAAIABJREFU9Q00rk4NpLMfzn45v49/+umn2/bfWfZms4LBYGDfbk4NZn3t5ZEjR5j29ea+1C/nbOdm05Iz3Ivzu9dms7GF+hzHsUXzFouF/eo7GzjbuhUymQxEBKPRyNonIrbk0Ilz3e+doNPpoFarYTAYYDQaYbfbwXEcdu/ejby8POh0uj9cHngrjxxnH511Pmi4pbBu2bIFy5cvx+XLl/Huu+9CKBRCq9Xi3Llz4DgON27cgNFoxM8//wwAzKywbt06FBYWYt68edi5cycEAgGuXr2KS5cugYiQlZXVwOa4atUqXLlyBSkpKTCZTGxdLgDs2rXLxaNlzpw5AOom8Y4dOyAQCGCxWHDs2DEAdbbHNWvWsPIcx0GpVKK6uhoCgQClpaVITU1lN53a2lpotVpUVVXhq6++wqxZs1BcXMyOrz8pP/roI2zYsIFNMoFAwLxanG3NnTsX//73v9lxBoMBBw8exNGjRzFr1ix8++23EIvFTFu+Z88eiEQiyOVySCQS7N27FxcuXIBCoYDRaGRrZ1evXo0333yTmT7mzZuHWbNmsZuD2WzGv//9bwB1prf6Srna2lr88ssvjQpHYWEhfvjhByZEFy5cwPbt26HT6WAymZjjwffff4/Vq1ejoqIC69atQ0lJCQCgqqoKW7duhV6vx7fffsvGdd68eY3euDZs2IB3332XrZm2WCxITk6GXq9HQkICNBpNgz7eS9zym/X/t3fm8VFU2R7/daez74lJSAKByBoQkLAYdEQHFUYdUFR0wFEEVF6CAsFlBIOogCzjQxADhGVUFhGfMCAECGHPECAhIRtkhSR09u6k0+mk96rz/sjUna4kbA5bQ30/n3w+6erqW+feqnOr6px7zunduzdCQkIQGBiIxx57DCaTiS2Sl8lk8PDwQFNTE77++msArRbRESNGoKamBi4uLoiKimJm/j//+c+wWq2Qy+Xw8/NjC8GB1nC4fv36sRxMCoVCtNi+Z8+ecHR0ZAvbBw4cCKBVUXr16gWO4+Di4oIZM2YAaM0/5OXlJZrVHR0doVAoIJfL4ePjAycnJ3Yx+/j4QC6Xw8HBAZGRkQgLCxMV0PrjH//ILKHDhw9HQEAAK9glk8lEQQcymQyPP/44GyOgNbCgb9++cHR0hMFgYEW3ACAsLAweHh6QyWTw9PSExWJB165dERAQABcXFygUCtZOaGioaCFJVFQUDAYD/P39IZPJ0NTUxBbGOzs7w8XFhY2Bk5MTevfujb59+7Y7z97e3ujXrx+AVoV3d3dHZGQk/Pz8mJwODg4YOHAg5s6di/79+6OhoQHu7u7su169ekEul6Nfv35sXCMjI0VBEkIoX79+/ZjMDQ0N8Pb2ZmMSHBwMJyenq12Wtxy7tAYLMgtKYjabWcQE8J/Hu7aV4YRHX1uFtG2rLXq9Hs7OzuwkX00WYX/hQhHuBra/FVxBPj4+ot/b3q2v1lehb4Iy3ihX62tHMguP0g4ODuzRWpg8bGlpaYFWq0VAQECHFlidTscU31YOgWv1RYi+4XledJ47Qq/XM/+sxWJpV/FPJpOx7bbymEwmNvEJq5lsr5PbxT1nDbY9ucJsbUtHJRyB9nfGtm215XpOlu3vBUUVtre9qB0cHODr63vdx+/o+6sp9rW4nmPZymz7v0wmu+Kx3d3dRX1vS9tzcaMTjUwmu243jO05E37T9nht25LJZExRhc93QlGvhV2+s0pI3I/YtbISEaZNm3bT2xUKHdsaPRISEm5a/iQhc4XtZ8EiCwBHjx5FSkrKXZOhQOLuwC6V9R//+AcaGhrw2WefwWQygeM4zJw5Ex9++CGampowYcIEHD16FGvWrMHFixfx1FNP4cknn0RcXBzOnTvHFsoXFhYiPj4ec+bMwZQpU5CUlASe57Fq1Sps3rwZGo0Ghw4dwrfffov//d//xR/+8AfMmTMHK1euZAvH6+vr8eyzz+KRRx5hqUNWrFiByspKTJ48GYMGDUJ0dDQ+//xz1NbWYtasWSgqKsKRI0dQVlaG7du3M1cJ0JrTadOmTdiyZQuKi4tx9OhRlJSUYNeuXSgvL8fu3btRUVGBlStXQqVSQavV4plnnkFTUxMWLlx41yf9kvgvuFJC4Y7+7oYk39nZ2aRWq6lnz5508eJFqqmpIbPZTJ07d6agoCDS6XT01VdfkU6nI5VKRdnZ2RQYGEgxMTG0e/duys/Pp/379xMRkcFgIJVKRYWFhXThwgVqamoinudp5cqVdPLkSbJYLBQfH0+5ubnUq1cv2rFjB1VUVFBdXR1xHEdERDk5OdS7d28qLCwkq9VKPM9TXV0dNTU1kb+/PxUWFpJSqaSKigoym810/PhxGjVqFOXl5dGZM2dIo9GQyWSilpYWKisro6ysLPr8889pyZIlZDQaafbs2RQfH09KpZIaGxuptraWFixYQJmZmZSQkECPPfYYpaWlkcViodDQUDIYDHfy9Ej8l9xTSb4FN83ly5fRpUsXyOVyEBEqKirQ3NyMt956C0lJSdDr9QgODobFYkFtbS08PDzg6uoKBwcHWCwWkQFB8LkJBhSdTgdnZ2fU19dDoVDA3d0dDQ0NCAgIgJOTk8hgYTaboVKpEBISIrIuCjKFhYWJrJFmsxlqtRoBAQHMuinsL1hfDQYDZDIZvLy8mAy2RhqtVgsPDw/o9XrodDoEBwdDLpdDqVSic+fO/5URSuLOct+kdeF5XqQIV3O5XA+Cq0Lg97hLJCRuhHvOdXMl5HI5AgMDAeC/VtSb1YaExM1Cel6SkLATJGWVkLATJGWVkLATJGWVkLAT7gtlTUtLw5NPPgkiwq5du/D666+L/FdAa9jU2rVrRds68nUVFRWxEDPb7Xv27Lnib9tytWO03aftfh19f6V9r3TsjrhSe1dq63r3b/s/z/Nscf3V+gMAx48fx5/+9KerynL8+HEUFBR0KGNubm67GGNbBgwYINpmNBrh6ekJjuOQn59/1f7fCe4LZR0yZAgOHDiAQ4cO4f3330dZWRmmT5+O6dOnswpiABAbG4uEhARRJbKIiAg4ODjgyy+/hE6nE7lvoqKiYDabodVq0blzZwQHB0OtVoOoteLayJEjMWDAgHbyFBQUYPLkyezz2bNn8c4772Dz5s1sm9lsxoYNG1hazrYV2wYMGMCKcgHAwIED0djYCCJiMthGnACt0TG2ET+2WK1W7N69G6NHj4ZOp0NVVRWys7Oxb98+DB06FF999RXbl4jw2muvYdy4cRg+fDhOnToFnufx4osv4qWXXkJjYyOOHTsGq9WKZcuWYciQIeA4Di0tLfDw8ADHcejVqxd27drF2qyrq0N4eDg4jhMV/ioqKhLVLYqPj0dcXBz7XFtbi7i4OHTv3h0HDx4U9alr165wdHTEpUuXYLVa4evrKwrW79y5M3r27NluQuE4DkVFRTAYDPj2228RHh6O06dPdzhut5P7Qll5nkdKSgq+//57JCQksBy4ERER2LlzJ4BWNw3HcXBzc2MRGH379mWFmNqWUgQAFxcXFj8LtAaLm81myGQyuLq6QqPRdBgtYjAYWIC0EHRORKK6Lc7OztDr9SyjYNtje3l5ITAwEA4ODpDJZHj99ddx9uxZ8DwPR0dHTJw4sV2pRyHG1Rbbu90DDzwAHx8feHp6oqysDFlZWbBYLGhubhZNUhqNBi+99BKqq6uxfPlyBAQEsKpyvr6+kMvlKC4uBs/zUKlUeOCBBwC0RueYTCbI5XJUVFRg3LhxrM2goCBkZWVh0aJF+Ne//sXkdXJyYjKrVCr069cPr7/+uqgP/fr1Q0REhChyxnbMdDodvvrqK5SUlLQLjwwLCxN9FvzqgtLW1dXBw8MDQ4cObXcebzf31KKI280TTzzB8tvaK1VVVVi+fDliYmKgVCrxxBNP3GmR7mvumxVMEhL2jlSYSkLiHsDulZWIRNXK/1uEbIK2aLVatsje9kmko/fYjuRrm4GwLcL7XkdwHHfdBa+uR57bja019koQUbsi0Nfa/0b6qdVqr5mJsW37bTMw3g3YtbISEWpqaliJCeGEmEwmpsAWiwUqlQo6nQ5ms5lZJbVaLdRqNTQaDbOoGgwGJCQkoO2j/p/+9CdkZGSwC0o46Rs3bkR9fT37LFgyBaMQ0JoTKDY2VmQo4nleFHeamJiIjz76CEStRaw0Gg2amprAcRxycnJw6dIltr2hoUE0mRgMBqhUKlitVuzatUtUKIuIUFtb22E1dI7jUFtbC7VafdUYWJPJBK1Wi8bGRmi1WlawSqvVdjg5CEYlYYLZtGkTs1Lb/tXW1opSla5Zs0YUgG+xWJiS2brKDAYD6uvrWcU3Aa1Wy7JBNjY2isbo8ccfZ64YoNVQJfyv1WpZkS9h/FtaWvDWW2+1G687rcB2q6xEBI1GIwpN02g0qKmpQUpKCsaOHQsiQn5+Pvr164eFCxfi1KlTKC4uxtq1azF9+nQMGzYMb775Jiu/uHXrVqxZswbl5eWiLBHPP/88EhISUFlZydJwGgwGbN68GVOnTmW5d4XgclsXDNCaeSIhIQFErcndGhsbUVJSIrrQhUReqampeO211zBnzhxUVlZixYoV+OCDD1BcXIwZM2Zg0qRJKCsrQ3V1NSwWC3788UdERUXh9OnTolSZgiKFh4eLqsQJY1dYWIiQkBCMGDGCuSWEi9X26eLUqVOIi4vD1KlTWd8qKyvx6aefIjU1tZ2vVK1W4+mnn2ZpUDmOw/Tp00VPBzzPo3///njooYdARCgvL8f8+fOxe/dulqHjwoULePPNN1FQUIDz588DaHUv/fDDD1i5cqXouPX19YiNjcWkSZMwe/ZsTJs2DUqlEhaLhVWwGzBgAEsOMGjQIPak9Pbbb2POnDlsvLKzs1FTUyOaOIgIJSUlrPLfncJulRUA1qxZg549e6Jnz54sydWcOXPg7++P0NBQAK0ukG7dusHf3x9ubm7IyMiAg4MDvLy80KtXLwwcOJDFirq4uCAoKAjV1dUiX19JSQni4uJw7NgxrFy5EkeOHMGZM2dgMpnw5ptv4uTJk+zuN2PGDFaASsDNzY3FshYWFkKtVqNPnz5sQvD09ESnTp3g5OSE4uJiGI1GjBo1Ck5OTnBzc8PUqVPRp08fLF++HL/++it8fHzw1ltvoaqqChkZGYiOjkZMTAwSExOZUri4uECv12PChAnt7qxmsxmHDh1CZGQkpkyZwiYXi8WCqqoqFBYWsnKXkZGRWLBgAR5//HF4enqyVKqffvopIiIiRJMaz/MwGo34+uuvcfr0aVitVphMJnh6erIJ1Wg0gud57NmzB5988gnkcjlCQkIQFBSEpUuXYseOHdBoNFAoFLh8+TLefPNNHDp0CECrL1alUsHJyUnUp2XLlmH8+PHYs2cPrFYrevToAXd3d5SVleHSpUsICgpC//79mYLbnp/s7GxUVFSw7xobGxEdHS16LTGZTMwVdSeRrMESv4uPPvoI48aNw6OPPnrdvxGedPz8/NCpU6dbKJ39ct/Es0rcPn7PI6FMJuswmbfE9WHXj8ESEvcTdqmsN2KGvxZms/mG3AZtOXz48O96lxGKVt1MbN+9BIgIOTk5N/U4VyIjIwNGo5FVpr8a1+t+UavVyMrKuuL3Fy5cQFVVFYDW2ja2lvjfA8dxomLLdxN2qawcx0GpVIKoNYqGiFBfX49du3bhyJEj7CLgeR4Gg4G5ayoqKpCeng4AKCsrQ3Z2NhoaGqDRaJCXl8csqhqNhhUxMplMrChSRxfCiy++yJTVYDCwi5DjOOzZswdmsxn79u1rF70huGJMJhMaGxtRU1ODkpISAP+5kLOzs1FeXi7alpWVxSp0C30kIiQmJmLPnj3Mkirsn5OTg8WLF0OpVIr6dODAAZH74vjx49DpdDh58iSOHDkCpVLZrq+5ubkoKytjn1NTU6FWqwEAR44cwYwZM1BfX4+JEydCqVQy2RoaGrB3714m065du1BXV8eMeII7S6/X49ChQ2hpaUF6ejo0Gg0yMzPx2WefQafTMaNPUVERCgoKYDKZsHz5cmbt/uGHH9gYHjt2DNXV1e2q6QGt1fd4nsehQ4dYMAFRa+X6nTt34pNPPrnq9XencPj888+ve+d169Z9/u677946aa6D2tpapKamIjk5GXq9HhMnTsTf/vY3rFq1Cu+//z68vb3h7u6Orl27QqfT4ciRIwgICMCuXbuwb98+HDhwAP3798emTZuwY8cO9OjRAw0NDdi/fz9TjBMnTsDT0xMPPPAAjEYjUlJSkJSUxNwuQUFBcHBwwO7du3H27Flm2S0pKUFYWBiOHj2KgIAAPPPMM4iJicG7776LN954A+np6QgJCYFcLodarUZ6ejoCAwNRWVmJgoIC7N69G3369EFlZSWrrmaxWJiL48yZMzh27BgsFgsqKysRGBgIuVyOpKQk/Prrr2hsbESfPn2QnZ2NxsZGuLu748MPP4RarUZTUxO0Wi0iIiKg0+kwdepUPPDAAzCZTDh79iwOHjwIuVyOtLQ0nD9/HkFBQQgNDYVcLkd1dTXOnz+Pb775BgUFBejduzc8PDzw008/QaVSoVu3bpg0aRKUSiXefvttbNmyBWPGjMGZM2fQq1cvrFu3DidOnGDBE8OGDYOrqyv69OkDZ2dnKBQK6PV67Nq1C0lJSZDJZDhx4gRqa2vh5uaGlJQU+Pn5oba2Ft27d8fJkyeRmpoKX19fpKeno3v37ujfvz+Sk5Ph6OgInucRExODkJAQuLu7w8vLC3K5HEePHkVYWBiWLFkCb29v7N+/HwcOHMDrr78Onufx/fffY8aMGXjwwQcRHh6O2tpa+Pn5oaCgAP7+/jCZTLe8mvq6devw7rvvftHRd3Z3Z9VoNMjJyYGvry8yMzMxffp0AK1K/D//8z9YuHAh8vPzAbTevaqrq2EymVBaWgqgtfJaRUUF/Pz8EBERgebmZjQ2NmLkyJGYOXMmHBwc0NjYCIvFAp7n4enpiby8PMTGxqK2thaFhYXMXXHq1Cl8+OGHyM3NRWVlJZv5c3JyIJPJMG3aNLi4uOCjjz6CxWJBYWEh64fBYIBSqYSbmxuCgoLQuXNnhISEQK1WQ6lUoqqqCqNHj2YhdnK5HAUFBRg/fjzMZjPy8vKYb/D06dOIj4+Hv78/6urq8MorryA/Px9NTU3o1asXBg0aBDc3NzYZubm54b333sOpU6dw8eJFmEwmfPzxx9Dr9Zg7dy6WLl2K4cOHszuSRqNBfn4+IiIi4OnpyRY9fPzxx1AoFGhpacGECRPw17/+Fe7u7pgyZQoiIiKQnp4OnudRX1+P9evX49SpUwCA6dOnw2AwICwsjD0uC+do0aJFUKvVmDRpEgwGA0JCQjB69GhWkxUAxo4di0ceeQR6vR7PPvssevfuDaC15KYQMfTiiy+iU6dOaGxsZE8+2dnZ4DgOP/74I/Ly8vD1119j7dq1AMAWasyYMQPz589Hfn4+SkpKYDKZWFTUtR7tbzX3hOtGeOxsW3TKnhAeGW80o6LFYmEFpa43VWrbxRh3GiJiZTfvpoySd+K6uuddNzKZzK4VFfj91eF+z2PZ3aCgttxIlbjbyd12XdndY7CExP2KXSrrTz/9JHqU4zjupljw2i4zvF7WrFnTTp7FixezJXtXory8HL/++usNH+9KzJ0797oLU+l0OsTHx1/x+4yMjBuSra6url20ksCpU6fw2Wef3faIoMTERJHl3N6xS2Xdt28f1q9fL3LRrFy5EkCroaKji6y+vl6UR+fkyZP45ZdfkJGRgbS0NLZPc3MziygBWvMWCQalefPmiZT50qVLICL83//9X7sF7V9//TUaGhrAcRwuXboEnufb+WOrq6uxb98+tgD/2LFj2LFjBw4fPozjx4+3u7hTUlJYxMiCBQuQnJyMtWvXoqWlBUSEVatWISYmRrReVxif7du3i7bp9Xr8/PPP0Ov12LNnD2bNmoUtW7awinYXLlxgLpH9+/dj+/btyMvLQ01NDaqqqqDT6bBq1SoUFxfj119/xapVq6DRaLBkyRJs3bpV5EPOycnB6tWrmZFGiKSZO3cu9u/fLxq3uro6zJs3D0uXLhVFUgmcOHEC69evR2VlJY4cOYJz584BANavX4+0tDRYrVb2uxMnTrSLzgGA+fPng+M4FmwQExOD06dPw2w2Y9asWQBaJ7O4uDjwPI+qqiosXry4XTu3G7tT1tTUVJw+fRpLlixBeno6fvnlF0ydOhUhISFYsWIFfv75Z2g0GuTm5gJoVcCNGzciOTlZ5OzOz8/HyZMncfr0aSxYsABHjx7FsWPHUFBQgG3btjHL7Zo1a1BRUYE1a9YgPj5etMB79erViI2NRWFhIRITE7Fq1Sp2YXl4eGDlypVoamrC3Llz8be//Y35OYHWu+rq1atx8uRJfPDBB1i9ejV4nkd+fj7S09Nx/PhxtoAdaPUNHj9+HJ9++inKysowcOBAhISEoHfv3oiNjWVy/fOf/4RWqxUlAIuJiYGXlxe+++47JCQkMPleffVV/P3vfwfP89i/fz8sFgs2bdqEzMxMbNy4EXV1ddi2bRsKCgoQHh4OIsLhw4fxxRdfIDMzE2fOnIFarcamTZvg6+sLhUKB/v3748EHHxQZirZs2YLm5macOXMGGzZswOTJkyGTyRAZGckCLoRzNW3aNKxYsQI7duzApUuXsHr1atHdMScnB0uXLsXu3buhUChQXl6OX375BRs2bMDixYuRn5+PL774ApcvX0ZOTg6MRiMWLVokOm8HDhzAjh070NDQgLlz5yIqKgrNzc3YsGED+vfvj+joaJYsbd68eVCpVDh48GC7nFa3m7vn7fk6CQ0NZbNccHAwS1r2xhtvwNXVFe7u7ggKCmIGG1dXVwwYMAAeHh6iXEkjR47E4MGD4erqii5duiAsLAw+Pj7w8/ODr68vgoKCAADDhw+Ht7c3Bg0ahPXr18PPz4+1MWbMGOh0Ojz22GPo0aMH/P39IZPJIJfLsW7dOvA8DxcXF0ycOBEKhUJkRPHy8sJrr72GsWPHwtHREUFBQejbty9CQ0PBcVy7Snc9evRAt27dcPnyZXh7e2Ps2LEAWpOF6XQ6ODk54ccff4STkxNcXV1FYzZ69Gg88cQT8Pb2Zkrk6uqKCRMmIDc3F4MGDUJ8fDwGDhyIy5cvIygoCO+99x4CAgLg7e2NoUOHokePHtDr9VAoFPDz80N4eDhmzZqFBx98EDNnzsRDDz0ELy8v/PGPf4SLi4vIYDZz5kzwPM/8tgEBAZDL5XjuuedEfRRkmjBhAvz8/ODj44PBgweLztvo0aPRqVMn9OjRAz169IBWq0V9fT3mz58PnucRGBiIP/zhD/D29sasWbPA8zweeeQR0dgvXboU/v7+sFqtGDx4MF5++WVoNBp4enoiMjIS/v7+8PLywsaNG+Hl5YWwsDB88cUXcHZ2vtHL9aZyT7huJO4eLBYLFArFNS3OgrvmVluB9Xp9u8lDQKvVwtXV9a5KeHfPu24k7h6uV/lul7vG9s7dFm9v71t+/JuJ3b2zCghGlWvRNoXKnZbnVmC7/lXIjHAlbNco345x6ej4V7Ia32qEtdv2il0q65dffokxY8YAAJKTk8HzPJKSklBQUACO45CdnY3Nmzdj8eLFkMlkKCgowMSJE5GdnY1//etf7aJQSkpKWKoUIeXK8uXLUVJSgm+//RYVFRVITU1lC/nnz58vsjLGxcVBWDOt1+uRnJzM5MrPz0dzczOz3gJgGSOSkpKQkpLCokaA1nIQBw8eFC36b2hoYMezWq2oqqpi65Q5jsOoUaMwe/ZsmEwmKBQKREVFwWQyIS4uDkSEjRs3AmiduLKzszFy5EgYjUbs3bsXR48ehUqlQnl5ORISElBeXo59+/bh3Llz2LdvH6qrq7F3717s3LkThYWFyMrKQnV1NZP37bff7jBK5cknn0RLSwsbB7VajSlTpgBoNZbZprUxm83Yv38/SktLkZaWxiaSmpoaXLp0CQ0NDSgsLGTrm8+dO4eMjAyYzWa2LDQrKwt1dXVISEgQBRt899130Ol0rM8CarUaOp0On3zyCZtAOI6D1WrFb7/9BqA1Hc+WLVtQX1+Pn3766fouzluI3Snr8ePHMXXqVBQUFKCxsRHDhg3DDz/8gKioKHTr1g06nQ5vv/02Bg0ahF27dqGyshJLly5FcHAw6urqsHHjRvTo0YO1l5KSgjNnzsDZ2Rn+/v7w8PDAN998g9DQUKxfvx4PP/wwAgMD2RrdV199FX/5y1+YsWHdunWYNm0ay7Dv5OSEd955Bw8//DD+8Y9/ICQkBHv37sXEiRNZYjOFQoGwsDB07doViYmJbH0q0JpGJSoqCkBrgPf48eNRWFjIjkdE8Pf3x+bNmzF+/HgMHDiQjYmjoyNiY2MRGhoKhUKBN954AwDQvXt3AK2PnsHBwcjLy0NLSwu2bt2KgIAAREdHY/bs2XjppZegVCpx+PBhFBYWIjk5GfX19bBYLOjfvz/27NmDwsJClmEfAIqLi9kk9txzz6GyshJAa4SOUqnEsGHDIJPJ4OPjg6KiIgCtfvLY2FhERkYCABQKBR5++GEma15eHhwcHODn54fQ0FBcuHABW7duRW5uLk6cOAF/f39069YNCoUCGRkZKC0tRUtLCywWCxITE5l/e8yYMRg+fDiKi4tx7tw59h5NRHj++ecxdOhQvPfee0hPT4eDgwN4nseiRYswYsQIEBGcnZ3x7LPPQq/Xt0uid0dom3Xuan+DBw+mO01zczPxPE9lZWVktVqJ53nSaDTse6vVSqWlpWSxWOjy5ctkNpupqqqK6uvrSaVSUUZGhqi93377jbZt20Z6vZ44jiMiopqaGmpubqa6ujoyGo1sX47jSKlUktVqZdsaGhqI53mqqKggnueJ53m6ePEicRxHGo2GeJ4nrVZLHMdRU1MFC2kdAAAMI0lEQVQT24fneTKbzaRSqUilUnXYV7VaTUqlkvR6PfE8T0TEfqvRaKi8vJwuXrxIJSUlTKbq6mqqra0lnueJ4zjieZ4MBoOoD6WlpWS1WqmqqorMZjNVVFRQRUUFERHp9Xqqq6ujpqYm1v/m5mayWCy0Zs0aSkxMFMlYWVnJ2i8vLyez2UxERKWlpWQymZjcRMTGqKqqipRKJV28eJH1ieM4MpvNxHEcGQwG1k9BJpVKRXq9nnQ6HVksFnau9Ho9mUwmMhgMZLFYRPII599gMNClS5fYb3iep9LSUpLJZMTzPOn1era9rq5ONM5ExM7T7eDfOtah/t1X1mBhYYLtek/h8VKok3K3rZsF/rPw/k7L1tLSAgcHh3Y1ZeyVyspKUXbMuwHJGvxv5HJ5OxN+W5/k3cjdcjG1LWpl79guyLAH7O6dVULifuWeU1ar1cqSdt9MJk2aJLLa/l5KS0uZVfRaaDSaa5beGDp0KFQq1Q3J0NjYiD//+c+ibdnZ2Zg0adINtXMljh49iq1bt4pcQ2azGZ06dQLP8+jSpQvOnj2LVatW3ZTjXS/CKqzfg9lsRk1NzU2W6Aa50stsR393g4GJiKi+vp60Wi2VlJQQz/O0fft29p3FYqHk5GR69NFHKTw8nD7++GPSaDT0/fff08yZMyk9PZ1UKhWtX7+eIiMjydPTk5YtW0ZErYaEvLw8mjdvHk2ePJkuXLjA2h0zZgy5u7tTZWUlVVRUkMlkIpVKRQMHDqT333+fXF1dmVFi7ty5NG7cODpw4ACFhoaS2WymnJwcqq2tpfHjx1Pfvn0pLS2NmpqaqKioiA4ePEjR0dEUExNDixcvphUrVtDzzz9PiYmJIsNSQUEBLVmyhJRKJTMOdenShfz9/emDDz4go9FI6enpIkPK9u3b6fDhw/Tss8/SlClTSK/X0+TJkyksLIz1TafTUXx8PHl7e9Ps2bOpvr6eGX+IiJYsWUJRUVG0f/9+ysjIIKVSSSUlJdTY2Mjke/XVV6lXr15UUVFBERERpFKp2HcFBQVkNBrJycmJpk2bRidOnKA+ffqQyWSivXv30urVq2nKlCmUkZFBr7zyCpnNZkpOTiZfX1967rnnWH+ysrJo3LhxNG/ePGpubqaamho6fPgwFRUVUW5uLs2cOZM++eQTZiwjajVqNTQ00LJlyygxMZEZ4gTD4AsvvEDh4eHk5ubGjHHnzp0jg8FAO3fuJLVaTbW1tWQ0GqmysvLmXcRX4GoGJrtTVsECLFgQfX19ieM4am5uJqJWZU1PT6fq6mqKiYkhq9VKHMdRXl4effnll5Senk5PP/00zZo1i7755hv68MMP2QkU2o2OjqaDBw+KLJljxoyhpKQkSktLI7PZTDzPU2BgILW0tNCIESOYFZTnebJaraTX62nw4MG0d+9eunjxIhmNRsrIyKD8/HwaNWoUs9TqdDqqqKggq9VKVquV9uzZQ4sXL6aXX36ZvvvuO3Z8nufp3XffpbNnz1JOTg61tLQQz/PUpUsX8vT0pAMHDtDHH39MJpOJ0tPTWV+am5vJ0dGRzp8/z6yldXV19NBDD4naTk1NpREjRlBVVRWdOXOGysrKKDMzk4iIFi5cSC+88AIdO3aMYmNjaevWrWQwGKi8vJxaWlqIiOijjz6iy5cvE8/zFBERQfX19URE5OnpSUajkUwmE8lkMlqwYAFZrVaKiIig8PBw4jiOGhoaqKqqisLDw9n5PXXqFAGgUaNGsfPQ2NhIRUVFVFtbSxaLRWRZF8b9mWeeodTUVCIi+uKLL6iuro66dOlC69evF1mny8rKiOd5UqlUZLFYyGQy0fLlyyktLY0sFgudOXOGdu7cSUVFRcTzPBmNRtEkcKu4p6zBgryC0YXnefa/TCa7rhUqRNTOaGP7ue0x2h5H+E7YJrTXto2OjnOt4wvHvlKbbX8jhN11dBxBto6OR0QiY9uV9rtaG233aTsutv+37XdHYyzIZDsGwH+yaDQ1NcFsNsPf3/+KfbY9dtuxtP2N7Vhe67pp279byT1lDW47WG2tu9czmNfap6PvO1oILmy7kqJc7eK+1rGv1Ob1yHU9cnSklFeT90bGzFYm2//bTnZXauNKYyDUJLqaLB0d73r7fzXuBou83SmrxP3L3aAwd5J7yhpM/17jaftIQ//OUNfRvh1l0he238jrwe1C6IvQx6vJ2HYcfs+xrveV4kaOc6sW8d+Mc3ajfbnd2KWyEhGrqG178pubm9GlSxc0NTUxRSwrK8PMmTNF+xERzp07h4MHD7JtQnQOz/PYuXMniouLWfFl25d8oXap7UnlOK5dhW9hX0EOQWZhm200kJBKRUAolSgEoQsyNDU14YUXXsBjjz2GlJQUtl/b41qtVnTv3p1VLRBKMdr2g+f5q1ZKNxgMrOK7UGLEaDSytCwCOp2OlXG0neiE/S0Wi+jd8amnnmL7tx0rYTIS+mAbQSSUG2mbYV8Yu19++QX5+fmidk0mU4e/sZXPVjYhhYtt8WZhnO50zmDATpWV4zi4ubmhsbERy5YtE82IMpkMzs7OSEpKAtDqH0tPT8eGDRvY7y0WC5ydnUVlBzMyMvDXv/4Vv/32G+RyOXQ6HV544QVs376dKZlarUZERAQWL14sOnnbt29vFzdpNpsxaNAgnDx5EkDr0jZXV1dEREQgPz8f2dnZiI6OBgCcPXsW33//PevDokWL2ML5WbNmYefOnQCAqqoqcByHDRs2QKvVoqWlBX379hUlZiMixMfHQ6lUsjqkx44dY7GbggIUFhaid+/eoklMyI0EtMaBent7Y+fOnXjllVcwZMgQBAcH46mnnmJ9AoBt27bh6aefZov0MzMzYTabMXToUPj7+yM6Olo0EZ09exZubm6ifFhCJYGmpib88MMP0Gg0WLhwIV5++WVWnmP79u0YMGAAfv75Z9E4Z2ZmYsOGDcjNzcW6detY+Qye5zFs2DB069YNP/30k+h81dXVoVOnTnB1dQXHcUzBs7KywHEc5syZw9rIyclBcHAwC664k9ilsioUCvj4+MDFxYVleQdaFdXLywtGoxG7d+8G0FpM+cEHH4SPjw/bz2AwQKfTifIE9e7dG6+++iq6d+8OuVwOb29vVsxYLpejoaEBDQ0N2LNnD06dOiVy+Ov1elH7AlqtFo8//jiAVsOHj48PAgMD0adPH5jNZmYw4TgOer2ehXC5u7vDaDRCp9OxJZJCuhh3d3c4ODhAoVDg9OnTmDVrFjw8PNgx5XI5mpqaRPL07dsXfn5+ICKUlpayu7S3t7donXRNTY3oaUOw5g4ZMgRPPPEEFi5ciCeffFJUYf2NN95AXFwcPD09wfM8zp8/j+rqaowdOxadO3fGo48+KnrX9Pb2hq+vr2ii9PX1xaVLl2C1Wlmfu3btiueff55Zfh0dHVm9Itv2hgwZgtzcXNTU1CAkJIRFJ1VWVuKll16CQqHA008/LUrJEhgYCAcHB/j4+MDBwYFNdn5+fnBycmITiYODA3x9feHk5MTO1Z3E7lw3twqtVguFQnHPrX+1V86dO4d58+Zh06ZNorxX9zr3lOvmVmFvKT7udQYNGoS9e/feaTHuKuzyMVhC4n5EUlYJCTvB7h6DhXdsIRN7ZGQkiIgZCSorK+Ho6Iju3btfNbOdhIS9YXfKCoBZKG19hmvXroVarcaPP/6IQYMG4Z133sHgwYMRERFxp8WVkLgp2N1jsEwmg9lsxsiRI/HUU0+x7a6urigoKMCkSZNYeYVt27bdQUklJG4ukutGQuIu4mquG7u7s0pI3K9IyiohYSdIyiohYSdIyiohYSdIyiohYSdIyiohYSdIynqfIISvZWZm3mlRJH4nkrLeJ8hkMnh6euLixYt3WhSJ34ldLjeUuHFkMhk6d+58p8WQ+C+Q7qz3EXK5HGFhYXdaDInfiaSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2gqSsEhJ2wg3lDZbJZCoA5bdOHAmJ+56uRBTQ0Rc3pKwSEhJ3DukxWELCTpCUVULCTpCUVULCTpCUVULCTpCUVULCTpCUVULCTpCUVULCTpCUVULCTpCUVULCTvh/RgNE2oDpKJgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb274c8ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The given file is not a photo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9GOI8ZHklr3",
        "outputId": "0ce58a89-ed4d-4cad-de20-b1ebdfe7bdb1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
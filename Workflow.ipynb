{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HETjw6mfjVh6"
      },
      "source": [
        "import cv2\r\n",
        "import imageio\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from nltk.translate.bleu_score import corpus_bleu\r\n",
        "import numpy as np\r\n",
        "from numpy import argmax\r\n",
        "import os\r\n",
        "from pickle import dump, load\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "from scipy.ndimage import gaussian_filter, uniform_filter\r\n",
        "import string\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "from tensorflow.keras.layers import add\r\n",
        "from tensorflow.keras.models import Model, load_model\r\n",
        "from tensorflow.keras.preprocessing.image import load_img\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToRcOKocjhDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a3554e-5194-493a-e593-5c94b8f48a16"
      },
      "source": [
        "IMAGE_WIDTH = 224\r\n",
        "IMAGE_HEIGHT = 224\r\n",
        "\r\n",
        "ROOT_DIR = \"drive/MyDrive/Colab Notebooks\"\r\n",
        "\r\n",
        "DATASET_PATH = os.path.join(ROOT_DIR, \"Dataset\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_PATH = os.path.join(ROOT_DIR, \"CaptionGenerator\")\r\n",
        "CAPTION_GENERATOR_DATASET_PATH = os.path.join(CAPTION_GENERATOR_PATH, \"Dataset\")\r\n",
        "CAPTION_GENERATOR_IMAGE_DATASET_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"Flicker8k_Dataset\")\r\n",
        "CAPTION_GENERATOR_TEXT_DATASET_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"Text\")\r\n",
        "CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"fit\")\r\n",
        "CAPTION_GENERATOR_IMAGES_PATH = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"img\")\r\n",
        "print(CAPTION_GENERATOR_TEXT_DATASET_PATH)\r\n",
        "\r\n",
        "CAPTION_GENERATOR_DESCRIPTIONS_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"descriptions.txt\")\r\n",
        "CAPTION_GENERATOR_FEATURES_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"features.pkl\")\r\n",
        "CAPTION_GENERATOR_TOKENIZER_FILENAME = os.path.join(CAPTION_GENERATOR_DATASET_PATH, \"tokenizer.pkl\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_TOKEN_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr8k.token.txt\")\r\n",
        "CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr_8k.trainImages.txt\")\r\n",
        "CAPTION_GENERATOR_TEST_IMAGES_FILENAME = os.path.join(CAPTION_GENERATOR_TEXT_DATASET_PATH, \"Flickr_8k.devImages.txt\")\r\n",
        "\r\n",
        "CAPTION_GENERATOR_TRAINING_EPOCHS = 20"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Colab Notebooks/CaptionGenerator/Dataset/Text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdtqVO6tZuDd"
      },
      "source": [
        "class ImageLoader:\r\n",
        "  def convolve(self, image_data, filter, parameter=3):\r\n",
        "    image_data = image_data[0]\r\n",
        "    if filter == \"\" or filter == \"none\":\r\n",
        "      pass\r\n",
        "    elif filter == \"gaussian\":\r\n",
        "      image_data = self.convolveGaussianFilter(image_data, parameter)\r\n",
        "    elif filter == \"uniform\":\r\n",
        "      image_data = self.convolveUniformFilter(image_data, parameter)\r\n",
        "    else:\r\n",
        "      print(\"Error: Unknown filter '\" + filter + \"'\")\r\n",
        "    image_data = np.expand_dims(image_data, axis=0)\r\n",
        "    return image_data\r\n",
        "\r\n",
        "  def convolveGaussianFilter(self, image_data, sigma=3):\r\n",
        "    return np.array(Image.fromarray(image_data)\r\n",
        "    .filter(ImageFilter.GaussianBlur(sigma)))\r\n",
        "\r\n",
        "  def convolveUniformFilter(self, image_data, size=3):\r\n",
        "    return np.array(Image.fromarray(image_data)\r\n",
        "    .filter(ImageFilter.UnsharpMask(size)))\r\n",
        "    #return gaussian_filter(image_data, size)\r\n",
        "\r\n",
        "  def getImageData(self, image):\r\n",
        "    return np.array(image)\r\n",
        "\r\n",
        "  def readAndShowImage(self, image_path):\r\n",
        "    image_data = self.readImage(image_path)\r\n",
        "    self.showImage(image_data)\r\n",
        "\r\n",
        "  def readImage(self, image_path, target_width, target_height):\r\n",
        "    if os.path.isfile(image_path):\r\n",
        "      #image_data = np.array(Image.open(image_path))\r\n",
        "      image_data = cv2.imread(image_path)[:,:,::-1]\r\n",
        "      image_data = self.resize(image_data, target_width, target_height)\r\n",
        "      image_data = np.expand_dims(image_data, axis=0)\r\n",
        "      return image_data\r\n",
        "    else:\r\n",
        "      print(\"ERROR: Invalid image path\")\r\n",
        "\r\n",
        "  def resize(self, image_data, target_width, target_height):\r\n",
        "    image_data = cv2.resize(image_data, (target_width, target_height))\r\n",
        "    return image_data\r\n",
        "\r\n",
        "  def showImage(self, image_data):\r\n",
        "    if len(image_data.shape) == 4:\r\n",
        "      image_data = image_data[0]\r\n",
        "    plt.imshow(image_data)\r\n",
        "    plt.xticks([])\r\n",
        "    plt.yticks([])\r\n",
        "    plt.show()"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_OK6F_jlFz"
      },
      "source": [
        "class CaptionGenerator:\r\n",
        "    \r\n",
        "    IMAGE_WIDTH = 0\r\n",
        "    IMAGE_HEIGHT = 0\r\n",
        "    \r\n",
        "    IMAGE_CLASSIFIER = None\r\n",
        "    \r\n",
        "    def __init__(self, image_width, image_height):\r\n",
        "        self.IMAGE_WIDTH = image_width\r\n",
        "        self.IMAGE_HEIGHT = image_height\r\n",
        "        \r\n",
        "        #self.IMAGE_CLASSIFIER = ImageClassifier(image_width, image_height)\r\n",
        "        #self.IMAGE_CLASSIFIER.loadModel()\r\n",
        "        \r\n",
        "    def calculateDescriptionMaxLength(self, descriptions):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        return max(len(d.split()) for d in lines)\r\n",
        "        \r\n",
        "    def cleanDescriptions(self, descriptions):\r\n",
        "        table = str.maketrans('', '', string.punctuation)\r\n",
        "        for key, description_list in descriptions.items():\r\n",
        "            for i in range(len(description_list)):\r\n",
        "                description = description_list[i]\r\n",
        "                description = description.split()\r\n",
        "                description = [word.lower() for word in description]\r\n",
        "                description = [w.translate(table) for w in description]\r\n",
        "                description = [word for word in description if len(word)>1]\r\n",
        "                description = [word for word in description if word.isalpha()]\r\n",
        "                description_list[i] = ' '.join(description)\r\n",
        "        \r\n",
        "    def convertPath(self, path):\r\n",
        "        validPath = \"\"\r\n",
        "        for char in path:\r\n",
        "            if char == '\\\\':\r\n",
        "                validPath += \"/\"\r\n",
        "            else:\r\n",
        "                validPath += char\r\n",
        "        return validPath\r\n",
        "    \r\n",
        "    def convertToLines(self, descriptions):\r\n",
        "        all_descriptions = list()\r\n",
        "        for key in descriptions.keys():\r\n",
        "            [all_descriptions.append(d) for d in descriptions[key]]\r\n",
        "        return all_descriptions\r\n",
        "    \r\n",
        "    def convertToVocabulary(self, descriptions):\r\n",
        "        all_descriptions = set()\r\n",
        "        for key in descriptions.keys():\r\n",
        "            [all_descriptions.update(d.split()) for d in descriptions[key]]\r\n",
        "        return all_descriptions\r\n",
        "    \r\n",
        "    def createSequences(self, tokenizer, max_length, description_list, photo, vocab_size):\r\n",
        "        X1, X2, y = list(), list(), list()\r\n",
        "        for description in description_list:\r\n",
        "          sequence = tokenizer.texts_to_sequences([description])[0]\r\n",
        "          for i in range(1, len(sequence)):\r\n",
        "            in_seq, out_seq = sequence[:i], sequence[i]\r\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\r\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\r\n",
        "            X1.append(photo)\r\n",
        "            X2.append(in_seq)\r\n",
        "            y.append(out_seq)\r\n",
        "        return np.array(X1), np.array(X2), np.array(y)\r\n",
        "    \r\n",
        "    def createTokenizer(self, descriptions, verbose=True):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        tokenizer = Tokenizer()\r\n",
        "        tokenizer.fit_on_texts(lines)\r\n",
        "        vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "          print(\"Vocabulary size: %d\" % vocab_size)\r\n",
        "\r\n",
        "        return tokenizer, vocab_size\r\n",
        "    \r\n",
        "    def dataGenerator(self, descriptions, photos, tokenizer, max_length, vocab_size):\r\n",
        "        while 1:\r\n",
        "          for key, desc_list in descriptions.items():\r\n",
        "            photo = photos[key][0]\r\n",
        "            in_img, in_seq, out_word = self.createSequences(tokenizer, max_length, desc_list, photo, vocab_size)\r\n",
        "            yield [in_img, in_seq], out_word\r\n",
        "    \r\n",
        "    def defineModel(self, vocab_size, max_length, verbose=False):\r\n",
        "        # Feature extractor model\r\n",
        "        inputs1 = Input(shape=(4096,))\r\n",
        "        fe1 = Dropout(0.5)(inputs1)\r\n",
        "        fe2 = Dense(256, activation=\"relu\")(fe1)\r\n",
        "        \r\n",
        "        # Sequence model\r\n",
        "        inputs2 = Input(shape=(max_length,))\r\n",
        "        se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\r\n",
        "        se2 = Dropout(0.5)(se1)\r\n",
        "        se3 = LSTM(256)(se2)\r\n",
        "        \r\n",
        "        # Decoder model\r\n",
        "        decoder1 = add([fe2, se3])\r\n",
        "        decoder2 = Dense(256, activation=\"relu\")(decoder1)\r\n",
        "        outputs = Dense(vocab_size, activation=\"softmax\")(decoder2)\r\n",
        "        \r\n",
        "        model = Model(inputs=[inputs1, inputs2], outputs=outputs)\r\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\r\n",
        "        \r\n",
        "        if verbose:\r\n",
        "            print(model.summary())\r\n",
        "            \r\n",
        "        plot_model(model, to_file=\"model.png\", show_shapes=True)\r\n",
        "        \r\n",
        "        return model\r\n",
        "    \r\n",
        "    def evaluateModel(self, model_filename, verbose=True):\r\n",
        "        train_descriptions, train_features = self.loadTrainingDataset(verbose)\r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions, verbose)\r\n",
        "        max_length = self.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "        test_descriptions, test_features = self.loadTestSet()\r\n",
        "        model = load_model(model_filename)\r\n",
        "        \r\n",
        "        actual, predicted = list(), list()\r\n",
        "        for key, description_list in test_descriptions.items():\r\n",
        "            yhat = self.generateDescription(model, tokenizer, test_features[key], max_length)\r\n",
        "            references = [d.split() for d in description_list]\r\n",
        "            actual.append(references)\r\n",
        "            predicted.append(yhat.split())\r\n",
        "            \r\n",
        "        print(\"Evaluated model: %s\" % model_filename)\r\n",
        "        print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\r\n",
        "        print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\r\n",
        "        print(\"BLEU-3: %f\" % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\r\n",
        "        print(\"BLEU-4: %f\" % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\r\n",
        "\r\n",
        "    def evaluateModels(self, directory=CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH):\r\n",
        "        for model in os.listdir(directory):\r\n",
        "          if(model.endswith(\".h5\")):\r\n",
        "            self.evaluateModel(os.path.join(directory, model))\r\n",
        "        \r\n",
        "    def extractFeatures(self, filename, output_file=CAPTION_GENERATOR_FEATURES_FILENAME, verbose=1):\r\n",
        "        model = VGG16()\r\n",
        "        model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\r\n",
        "        if(verbose >= 2):\r\n",
        "            print(model.summary())\r\n",
        "\r\n",
        "        if isinstance(filename, np.ndarray):\r\n",
        "            image = preprocess_input(filename)\r\n",
        "            feature = model.predict(image, verbose=0)\r\n",
        "            return feature\r\n",
        "\r\n",
        "        else:            \r\n",
        "            if os.path.isdir(filename):\r\n",
        "                features = dict()\r\n",
        "                for name in os.listdir(filename):\r\n",
        "                    filename = filename + '/' + name\r\n",
        "                    image = load_img(filename, target_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "                    image = img_to_array(image)\r\n",
        "                    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\n",
        "                    image = preprocess_input(image)\r\n",
        "                    feature = model.predict(image, verbose=0)\r\n",
        "                    image_id = name.split('.')[0]\r\n",
        "                    features[image_id] = feature\r\n",
        "                    if(verbose >= 3):\r\n",
        "                        print('>%s' % name) \r\n",
        "            \r\n",
        "                if verbose >= 1:\r\n",
        "                    print(\"Extracted Features: %d\" % len(features))\r\n",
        "                \r\n",
        "                dump(features, open(DATASET_PATH + output_file, 'wb'))\r\n",
        "            \r\n",
        "                return features\r\n",
        "                \r\n",
        "            elif os.path.isfile(filename):\r\n",
        "                image = load_img(filename, target_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "                image = img_to_array(image)\r\n",
        "                image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\n",
        "                image = preprocess_input(image)\r\n",
        "                feature = model.predict(image, verbose=0)\r\n",
        "                return feature\r\n",
        "            \r\n",
        "    \r\n",
        "    def fitCaptioningModel(self, train_descriptions, train_features, tokenizer, vocab_size, max_length, epochs=20):\r\n",
        "        model = self.defineCaptioningModel(vocab_size, max_length, summarize=True)\r\n",
        "        steps = len(train_descriptions)\r\n",
        "        for i in range(epochs):\r\n",
        "            generator = self.dataGenerator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\r\n",
        "            model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=2)\r\n",
        "            model.save(os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % i))\r\n",
        "\r\n",
        "    def fitTrainingModelWithProgressiveLoading(self, \r\n",
        "                                               verbose=True, \r\n",
        "                                               epochs=CAPTION_GENERATOR_TRAINING_EPOCHS,\r\n",
        "                                               initial_epoch=0):\r\n",
        "        train_descriptions, train_features = self.loadTrainingDataset(verbose)\r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions, verbose)\r\n",
        "        max_length = self.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "        if initial_epoch == 0:\r\n",
        "          model = self.defineModel(vocab_size, max_length, verbose)\r\n",
        "        else:\r\n",
        "          model_path = os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % int(initial_epoch - 1))\r\n",
        "          model = load_model(model_path)\r\n",
        "          if verbose:\r\n",
        "            print(\"Load model %s\" % model_path)\r\n",
        "\r\n",
        "        for epoch in range(initial_epoch, epochs):\r\n",
        "          print(\"Epoch %d\" % epoch)\r\n",
        "          generator = self.dataGenerator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\r\n",
        "          model.fit(generator, epochs=1, steps_per_epoch=len(train_descriptions))\r\n",
        "          model.save(os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_%d.h5\" % epoch))\r\n",
        "    \r\n",
        "    def generateAndSaveTokenizer(self, \r\n",
        "                                 filename=CAPTION_GENERATOR_TOKENIZER_FILENAME,\r\n",
        "                                 verbose=True, \r\n",
        "                                 descriptions_filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME):\r\n",
        "        train = self.loadSet(CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME)\r\n",
        "        if verbose:\r\n",
        "            print(\"Dataset: %d\" % len(train))\r\n",
        "        \r\n",
        "        train_descriptions = self.loadCleanDescriptions(train, filename=descriptions_filename)\r\n",
        "        if verbose:\r\n",
        "            print(\"Descriptions: train=%d\" % len(train_descriptions))\r\n",
        "        \r\n",
        "        tokenizer = self.createTokenizer(train_descriptions)\r\n",
        "        dump(tokenizer, open(filename, \"wb\"))\r\n",
        "        \r\n",
        "        if verbose:\r\n",
        "            print(\"Tokenizer saved to file '\" + filename + \"'\")\r\n",
        "    \r\n",
        "    def generateCaption(self, \r\n",
        "                        image_path, \r\n",
        "                        show_image=True, \r\n",
        "                        captioning_model=os.path.join(CAPTION_GENERATOR_TRAIN_MODEL_FIT_PATH, \"model_0.h5\")):\r\n",
        "    #    image_path = self.convertPath(image_path)\r\n",
        "    #    image = self.readImageFile(image_path)\r\n",
        "    #    self.IMAGE_CLASSIFIER.predict(image)\r\n",
        "        #print(os.path.join(CAPTION_GENERATOR_IMAGES_PATH, image_path))\r\n",
        "        #if not os.path.isfile(os.path.join(CAPTION_GENERATOR_IMAGES_PATH, image_path)):\r\n",
        "        #    print(\"Invalid image path\")\r\n",
        "        #    return\r\n",
        "    \r\n",
        "        tokenizer = load(open(CAPTION_GENERATOR_TOKENIZER_FILENAME, \"rb\"))\r\n",
        "        max_length = 34\r\n",
        "        model = load_model(captioning_model)\r\n",
        "        \r\n",
        "        #if show_image:\r\n",
        "        #    image = plt.imread(image_path)\r\n",
        "        #    plt.xticks([])\r\n",
        "        #    plt.yticks([])\r\n",
        "        #    plt.imshow(image)\r\n",
        "        #    plt.show()\r\n",
        "            \r\n",
        "        \r\n",
        "        photo = self.extractFeatures(image_path)\r\n",
        "        caption = self.generateDescription(model, tokenizer, photo, max_length)\r\n",
        "        caption = caption[9: len(caption)-7]\r\n",
        "            \r\n",
        "        return caption\r\n",
        "        \r\n",
        "    def generateDescription(self, model, tokenizer, photo, max_length):\r\n",
        "        in_text = \"startseq\"\r\n",
        "        for i in range(max_length):\r\n",
        "            sequence = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "            sequence = pad_sequences([sequence], maxlen=max_length)\r\n",
        "            yhat = model.predict([photo, sequence], verbose=0)\r\n",
        "            yhat = argmax(yhat)\r\n",
        "            word = self.wordFromId(yhat, tokenizer)\r\n",
        "            if word is None:\r\n",
        "                break\r\n",
        "            \r\n",
        "            in_text += ' ' + word\r\n",
        "            \r\n",
        "            if word == 'endseq':\r\n",
        "                break\r\n",
        "        return in_text\r\n",
        "\r\n",
        "    def getMaxLength(self, descriptions):\r\n",
        "        lines = self.convertToLines(descriptions)\r\n",
        "        return max(len(description.split()) for description in lines)\r\n",
        "        \r\n",
        "    def getTextFileContent(self, filename):\r\n",
        "        file = open(filename, 'r')\r\n",
        "        text = file.read()\r\n",
        "        file.close()\r\n",
        "        return text\r\n",
        "        \r\n",
        "    def loadCleanDescriptions(self, \r\n",
        "                              dataset, \r\n",
        "                              descriptions_filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME):\r\n",
        "        doc = self.getTextFileContent(descriptions_filename)\r\n",
        "        descriptions = dict()\r\n",
        "        for line in doc.split('\\n'):\r\n",
        "            tokens = line.split()\r\n",
        "            image_id, image_description = tokens[0], tokens[1:]\r\n",
        "            if image_id in dataset:\r\n",
        "                if image_id not in descriptions:\r\n",
        "                    descriptions[image_id] = list()\r\n",
        "                description = 'startseq ' + ' '.join(image_description) + ' endseq'\r\n",
        "                descriptions[image_id].append(description)\r\n",
        "        return descriptions\r\n",
        "\r\n",
        "    def loadDescriptions(self, filename):\r\n",
        "        text = self.getTextFileContent(filename)\r\n",
        "\r\n",
        "        mapping = dict()\r\n",
        "        for line in text.split('\\n'):\r\n",
        "            tokens = line.split()\r\n",
        "            if len(line) < 2:\r\n",
        "                continue\r\n",
        "            image_id, image_description = tokens[0], tokens[1:]\r\n",
        "            image_id = image_id.split('.')[0]\r\n",
        "            image_description = ' '.join(image_description)\r\n",
        "            if image_id not in mapping:\r\n",
        "                mapping[image_id] = list()\r\n",
        "            mapping[image_id].append(image_description)\r\n",
        "        return mapping\r\n",
        "    \r\n",
        "    def loadPhotoFeatures(self, dataset, features_filename=CAPTION_GENERATOR_FEATURES_FILENAME):\r\n",
        "        all_features = load(open(features_filename, 'rb'))\r\n",
        "        features = {k: all_features[k] for k in dataset}\r\n",
        "        return features\r\n",
        "    \r\n",
        "    def loadSet(self, filename):\r\n",
        "        doc = self.getTextFileContent(filename)\r\n",
        "        dataset = list()\r\n",
        "        for line in doc.split('\\n'):\r\n",
        "            if len(line) < 1:\r\n",
        "                continue\r\n",
        "            identifier = line.split('.')[0]\r\n",
        "            dataset.append(identifier)\r\n",
        "        return set(dataset)\r\n",
        "\r\n",
        "    def loadTestSet(self, verbose=True):\r\n",
        "        test = self.loadSet(CAPTION_GENERATOR_TEST_IMAGES_FILENAME)\r\n",
        "        test_descriptions = self.loadCleanDescriptions(test)\r\n",
        "        test_features = self.loadPhotoFeatures(test)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "          print(\"Dataset: %d\" % len(test))\r\n",
        "          print(\"Descriptions: test=%d\" % len(test_descriptions))\r\n",
        "          print(\"Photos: test=%d\" % len(test_features))\r\n",
        "\r\n",
        "        return test_descriptions, test_features\r\n",
        "\r\n",
        "    def loadTrainingDataset(self, verbose=True):\r\n",
        "        train = self.loadSet(CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME)\r\n",
        "        train_descriptions = self.loadCleanDescriptions(train)\r\n",
        "        train_features = self.loadPhotoFeatures(train)\r\n",
        "        if verbose:\r\n",
        "          print(\"Dataset: %d\" % len(train))\r\n",
        "          print(\"Descriptions: train=%d\" % len(train_descriptions))\r\n",
        "          print(\"Photos: train=%d\" % len(train_features))\r\n",
        "\r\n",
        "        return train_descriptions, train_features\r\n",
        "    \r\n",
        "    def prepareImageCaptioningTrainDataset(self):\r\n",
        "        descriptions = self.loadDescriptions(CAPTION_GENERATOR_TOKEN_FILENAME)\r\n",
        "        self.cleanDescriptions(descriptions)\r\n",
        "        vocabulary = self.convertToVocabulary(descriptions)\r\n",
        "        self.saveDescriptions(descriptions)\r\n",
        "        \r\n",
        "    def prepareTestDataset(self):\r\n",
        "        filename = CAPTION_GENERATOR_TEST_IMAGES_FILENAME\r\n",
        "        test = self.loadSet(filename)\r\n",
        "        print(\"Dataset: %d\" % len(test))\r\n",
        "        \r\n",
        "        test_descriptions = self.loadCleanDescriptions(test)\r\n",
        "        print(\"Descriptions: test=%d\" % len(test_descriptions))\r\n",
        "        \r\n",
        "        test_features = self.loadPhotoFeatures(CAPTION_GENERATOR_FEATURES_FILENAME, test)\r\n",
        "        print(\"Photos: test=%d\" % len(test_features))\r\n",
        "        \r\n",
        "        return test_descriptions, test_features\r\n",
        "        \r\n",
        "    def prepareTrainingDataset(self):\r\n",
        "        filename = CAPTION_GENERATOR_TRAIN_IMAGES_FILENAME\r\n",
        "        train = self.loadSet(filename)\r\n",
        "        print(\"Dataset: %d\" % len(train))\r\n",
        "        \r\n",
        "        train_descriptions = self.loadCleanDescriptions(train)\r\n",
        "        print(\"Descriptions: train=%d\" %len(train_descriptions))\r\n",
        "        \r\n",
        "        train_features = self.loadPhotoFeatures(train, CAPTION_GENERATOR_FEATURES_FILENAME)\r\n",
        "        print(\"Photos: train=%d\" % len(train_features))   \r\n",
        "        \r\n",
        "        tokenizer, vocab_size = self.createTokenizer(train_descriptions)\r\n",
        "        print(\"Vocabulary size: %d\" % vocab_size)\r\n",
        "        \r\n",
        "        max_length = self.calculateDescriptionMaxLength(train_descriptions)\r\n",
        "        print(\"Description length: %d\" % max_length)\r\n",
        "        \r\n",
        "        return train_descriptions, train_features, tokenizer, vocab_size, max_length\r\n",
        "    \r\n",
        "    def readImageFile(self, image_path):\r\n",
        "        if not os.path.isfile(image_path):\r\n",
        "            print(\"Unknow path\")\r\n",
        "            return None\r\n",
        "        else:\r\n",
        "            image = cv2.imread(image_path)\r\n",
        "            image = cv2.resize(image, (self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\r\n",
        "            image = np.expand_dims(image, axis=0)\r\n",
        "            return image\r\n",
        "        \r\n",
        "    def saveDescriptions(self, \r\n",
        "                         descriptions=None, \r\n",
        "                         filename=CAPTION_GENERATOR_DESCRIPTIONS_FILENAME,\r\n",
        "                         verbose=True):\r\n",
        "        print(filename)\r\n",
        "        if descriptions == None:\r\n",
        "          descriptions = self.loadDescriptions(CAPTION_GENERATOR_TOKEN_FILENAME)\r\n",
        "          self.cleanDescriptions(descriptions)\r\n",
        "          vocabulary = self.convertToVocabulary(descriptions)\r\n",
        "          \r\n",
        "          if verbose:\r\n",
        "            print(\"Loaded: %d\" % len(descriptions))\r\n",
        "            print(\"Vocabulary size: %d\" % len(vocabulary))\r\n",
        "\r\n",
        "        lines = list()\r\n",
        "        for key, description_list in descriptions.items():\r\n",
        "            for description in description_list:\r\n",
        "                lines.append(key + ' ' + description)\r\n",
        "        data = '\\n'.join(lines)\r\n",
        "        file = open(filename, 'w')\r\n",
        "        file.write(data)\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    def wordFromId(self, integer, tokenizer):\r\n",
        "        for word, index in tokenizer.word_index.items():\r\n",
        "            if index == integer:\r\n",
        "                return word\r\n",
        "        return None"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYVeklxfaNTV"
      },
      "source": [
        "class ImageClassifier:\r\n",
        "\r\n",
        "    IMAGE_CLASSIFIER_PATH = os.path.join(ROOT_DIR, \"ImageClassifier\")\r\n",
        "    FIT_DIR_PATH = os.path.join(IMAGE_CLASSIFIER_PATH, \"fit\")\r\n",
        "    \r\n",
        "    DATASETS_PATH = \"D:/Cours/Cesi/A5/UE/Option - Data Science/Projet/Livrable 2/Datasets/extracted\"\r\n",
        "    CLASS_NAMES = ['Painting', 'Photo', 'Schematics', 'Sketch', 'Text']\r\n",
        "    \r\n",
        "    VALIDATION_SPLIT = 0.3\r\n",
        "    \r\n",
        "    IMAGE_WIDTH = 0\r\n",
        "    IMAGE_HEIGHT = 0\r\n",
        "    \r\n",
        "    MODEL = None\r\n",
        "    EPOCHS = 0\r\n",
        "    HISTORY = None\r\n",
        "    \r\n",
        "    def __init__(self, image_width, image_height, model=\"model_0.780.h5\"):\r\n",
        "        self.IMAGE_WIDTH = image_width\r\n",
        "        self.IMAGE_HEIGHT = image_height\r\n",
        "\r\n",
        "        self.MODEL = load_model(os.path.join(self.FIT_DIR_PATH, model))\r\n",
        "        \r\n",
        "    def buildModel(self, dropout_rate=0, kernel_regularizer_l1=0.00, kernel_regularizer_l2=0.0):\r\n",
        "        model = tf.keras.Sequential([\r\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 3)),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomRotation(10),\r\n",
        "            tf.keras.layers.experimental.preprocessing.RandomZoom((0.2, 0.5)),\r\n",
        "            tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", \r\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\r\n",
        "            tf.keras.layers.Dropout(dropout_rate),\r\n",
        "            tf.keras.layers.Flatten(),\r\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\", \r\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l1_l2(l1=kernel_regularizer_l1, l2=kernel_regularizer_l2)),\r\n",
        "            tf.keras.layers.Dense(len(self.CLASS_NAMES))\r\n",
        "        ])\r\n",
        "        \r\n",
        "        model.compile(optimizer=\"adam\",\r\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "                           metrics=[\"accuracy\"])\r\n",
        "        \r\n",
        "        plot_model(model, to_file=\"model.png\", show_shapes=True)\r\n",
        "\r\n",
        "        return model\r\n",
        "        \r\n",
        "    def fit(self, \r\n",
        "            epochs, \r\n",
        "            save_path=None, \r\n",
        "            model_filename=\"ImageClassifierModel.h5\",\r\n",
        "            show_training_results=False, \r\n",
        "            dropout_rate=0, \r\n",
        "            kernel_regularizer_l1=0.01, \r\n",
        "            kernel_regularizer_l2=0.01):\r\n",
        "        train_dataset, test_dataset = self.generateDatasets()\r\n",
        "        self.MODEL = self.buildModel(dropout_rate, kernel_regularizer_l1, kernel_regularizer_l2)\r\n",
        "        self.EPOCHS = epochs\r\n",
        "        \r\n",
        "        earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\r\n",
        "        checkpointsCallback = tf.keras.callbacks.ModelCheckpoint(os.path.join(save_path, \"model_{val_accuracy:.3f}.h5\"),\r\n",
        "                                           save_best_only=True,\r\n",
        "                                           save_weights_only=False,\r\n",
        "                                           monitor='val_accuracy')\r\n",
        "        self.HISTORY = self.MODEL.fit(train_dataset, \r\n",
        "                                      validation_data=test_dataset, \r\n",
        "                                      epochs=epochs, \r\n",
        "                                      callbacks=[earlyStoppingCallback, checkpointsCallback])\r\n",
        "        \r\n",
        "        if save_path != None:\r\n",
        "            self.MODEL.save(os.path.join(save_path, model_filename))\r\n",
        "            \r\n",
        "        if show_training_results:\r\n",
        "            self.showTrainingResults()\r\n",
        "    \r\n",
        "    def generateDatasets(self):\r\n",
        "        datasets = []\r\n",
        "        \r\n",
        "        for subset_label in ['training', 'validation']:\r\n",
        "            datasets.append(tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "            self.DATASETS_PATH,\r\n",
        "            labels=\"inferred\",\r\n",
        "            label_mode=\"int\",\r\n",
        "            validation_split=self.VALIDATION_SPLIT,\r\n",
        "            subset=subset_label,\r\n",
        "            seed=42,\r\n",
        "            color_mode=\"rgb\",\r\n",
        "            image_size=(self.IMAGE_WIDTH, self.IMAGE_HEIGHT)))\r\n",
        "        return datasets[0], datasets[1]\r\n",
        "\r\n",
        "    def isPhoto(self, image_data):\r\n",
        "      if self.MODEL == None:\r\n",
        "        print(\"ERROR: Model is not defined\")\r\n",
        "        return\r\n",
        "      \r\n",
        "      prediction = self.MODEL.predict(image_data)\r\n",
        "      if np.argmax(prediction) == self.CLASS_NAMES.index('Photo'):\r\n",
        "        return True\r\n",
        "      else:\r\n",
        "        return False\r\n",
        "      print(np.argmax(prediction))\r\n",
        "    \r\n",
        "    def loadModel(self, model_path=\"ImageClassifier/ImageClassifier.h5\", add_softmax_layer=True):\r\n",
        "        model = tf.keras.models.load_model(model_path)\r\n",
        "        if add_softmax_layer:\r\n",
        "            model.add(tf.keras.layers.Softmax())\r\n",
        "        self.MODEL = model\r\n",
        "        \r\n",
        "    def modelSummary(self):\r\n",
        "        self.MODEL.summary()\r\n",
        "        \r\n",
        "    def predict(self,\r\n",
        "                image_data,\r\n",
        "                model_path=\"model_0.780.h5\",\r\n",
        "                verbose=False):\r\n",
        "      if not model_path.endswith(\".h5\"):\r\n",
        "        print(\"ERROR: Invalid classifier model\")\r\n",
        "        return\r\n",
        "      \r\n",
        "      print(image_data.shape)\r\n",
        "      model = load_model(os.path.join(self.FIT_DIR_PATH, model_path))\r\n",
        "      #prediction = model.predict(tf.convert_to_tensor(image))\r\n",
        "      prediction = model.predict(image_data)\r\n",
        "      predicted_class_id = np.argmax(prediction)\r\n",
        "      predicted_class = self.CLASS_NAMES[predicted_class_id]\r\n",
        "      print(predicted_class)\r\n",
        "      return predicted_class, predicted_class_id\r\n",
        "        \r\n",
        "    def showTrainingResults():\r\n",
        "        epochs_range = range(self.EPOCHS)\r\n",
        "    \r\n",
        "        plt.figure(figsize=(8, 8))\r\n",
        "        plt.subplot(1, 2, 1)\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['accuracy'], label=\"Training accuracy\")\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['val_accuracy'], label=\"Validation accuracy\")\r\n",
        "        plt.legend()\r\n",
        "        plt.title(\"Training and validation accuracy\")\r\n",
        "\r\n",
        "        plt.subplot(1, 2, 2)\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['loss'], label=\"Training loss\")\r\n",
        "        plt.plot(epochs_range, self.HISTORY.history['val_loss'], label=\"Validation loss\")\r\n",
        "        plt.legend()\r\n",
        "        plt.title(\"Training and validation loss\")\r\n",
        "\r\n",
        "        plt.show()"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVa79ynRjuSi",
        "outputId": "5bbe734d-f1f1-4e46-e2f9-9f3d68d765b4"
      },
      "source": [
        "captionGenerator = CaptionGenerator(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "train_descriptions, train_features = captionGenerator.loadTrainingDataset()\r\n",
        "tokenizer, vocab_size = captionGenerator.createTokenizer(train_descriptions)\r\n",
        "max_length = captionGenerator.getMaxLength(train_descriptions)\r\n",
        "\r\n",
        "#captionGenerator.defineModel(vocab_size, max_length)\r\n",
        "#captionGenerator.saveDescriptions()\r\n",
        "\r\n",
        "#train_descriptions, train_features = captionGenerator.loadTrainingDataset()\r\n",
        "\r\n",
        "#tokenizer, vocab_size = captionGenerator.createTokenizer(train_descriptions)\r\n",
        "\r\n",
        "#train_dataset, train_features, tokenizer, vocab_size, max_length = captionGenerator.prepareTrainingDataset()\r\n",
        "\r\n",
        "#captionGenerator.fitTrainingModelWithProgressiveLoading(epochs=20)\r\n",
        "\r\n",
        "#captionGenerator.evaluateModels()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n",
            "Vocabulary size: 7579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f7433eeac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "OO-rw_V3ajFL",
        "outputId": "e9b284fe-b02d-43b8-e56d-fe395f6adf94"
      },
      "source": [
        "image_filename = \"text1.png\"\r\n",
        "filter = \"gaussian\"\r\n",
        "size = 1\r\n",
        "revert = False\r\n",
        "\r\n",
        "def main(revert=False):\r\n",
        "    # Chargement de l'image\r\n",
        "    imageLoader = ImageLoader()\r\n",
        "    image_path = os.path.join(DATASET_PATH, image_filename)\r\n",
        "    image_data = imageLoader.readImage(image_path, IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "\r\n",
        "    # Affichage initial\r\n",
        "    imageLoader.showImage(image_data) \r\n",
        "\r\n",
        "    if revert:  \r\n",
        "\r\n",
        "      # Convolution\r\n",
        "      image_data = imageLoader.convolve(image_data, filter, size)\r\n",
        "      if filter != \"\":\r\n",
        "        imageLoader.showImage(image_data)  \r\n",
        "\r\n",
        "      # Classification\r\n",
        "      imageClassifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "      if not imageClassifier.isPhoto(image_data):\r\n",
        "        print(\"The given file is not a photo\")\r\n",
        "        return\r\n",
        "\r\n",
        "    else: \r\n",
        "\r\n",
        "      # Classification\r\n",
        "      imageClassifier = ImageClassifier(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "      if not imageClassifier.isPhoto(image_data):\r\n",
        "        print(\"The given file is not a photo\")\r\n",
        "        return\r\n",
        "\r\n",
        "      # Convolution\r\n",
        "      image_data = imageLoader.convolve(image_data, filter, size)\r\n",
        "      if filter != \"\":\r\n",
        "        imageLoader.showImage(image_data)\r\n",
        "\r\n",
        "    # Génération de la légende\r\n",
        "    captionGenerator = CaptionGenerator(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "    caption = captionGenerator.generateCaption(image_data)\r\n",
        "    print(caption)\r\n",
        "\r\n",
        "main(revert)\r\n",
        "\r\n",
        "\r\n",
        "#image_data = image_data.reshape(image_data.shape[0], image_data.shape[1], image_data.shape[2], 1)\r\n",
        "#image_path = os.path.join(CAPTION_GENERATOR_IMAGE_DATASET_PATH, \"47871819_db55ac4699.jpg\")\r\n",
        "#image_path = os.path.join(DATASET_PATH, \"photo2.jpg\")\r\n",
        "#print(os.path.isfile(image_path))\r\n",
        "#image_data = imageLoader.readImage(image_path)\r\n",
        "#imageLoader.resize(image_data, IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        "#image_data = imageLoader.convolveGaussianFilter(image_data, 3)\r\n",
        "#imageLoader.showImage(image_data)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb275d79e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The given file is not a photo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9GOI8ZHklr3",
        "outputId": "0ce58a89-ed4d-4cad-de20-b1ebdfe7bdb1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}